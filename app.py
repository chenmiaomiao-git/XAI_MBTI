
import gradio as gr
import os
import tempfile
import numpy as np
import soundfile as sf
from datetime import datetime
from typing import List, Tuple, Optional, Dict, Any
import time

# å¯¼å…¥è‡ªå®šä¹‰æœåŠ¡æ¨¡å—
from audio_service import AudioService
from chat_service import ChatService

# è¿™äº›å‡½æ•°å·²ç»ç§»åŠ¨åˆ°AudioServiceå’ŒChatServiceæ¨¡å—ä¸­

# å‘é€èŠå¤©è¯·æ±‚å‡½æ•°å·²ç§»åŠ¨åˆ°ChatServiceæ¨¡å—

# å¤„ç†éŸ³é¢‘è¾“å…¥
def handle_audio(audio, history, lora_path, prompt_choice, promptFormat_choice, tts_choice):
    # è°ƒç”¨handle_chatå‡½æ•°å¤„ç†éŸ³é¢‘è¾“å…¥
    chatbot_output, chat_history_output, audio_output, _ = handle_chat(None, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, audio)
    return chatbot_output, chat_history_output, audio_output, ""

# å¤„ç†èŠå¤©æäº¤
def handle_chat(message, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, audio=None):
    # å¦‚æœæä¾›äº†éŸ³é¢‘ï¼Œå…ˆè¿›è¡Œè¯­éŸ³è¯†åˆ«
    if audio is not None:
        try:
            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼
            if isinstance(audio, str):
                # å¦‚æœéŸ³é¢‘æ˜¯å­—ç¬¦ä¸²è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨è¯¥è·¯å¾„
                audio_file_path = audio
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºåç»­å¤„ç†
                temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
                import shutil
                shutil.copy(audio_file_path, temp_audio.name)
                temp_audio.close()
            elif isinstance(audio, tuple) and len(audio) >= 2:
                # å¦‚æœéŸ³é¢‘æ˜¯å…ƒç»„æ ¼å¼(é‡‡æ ·ç‡, æ•°æ®)ï¼Œä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                sf.write(temp_audio.name, audio[1], audio[0])
                temp_audio.close()
            else:
                # ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
                print(f"éŸ³é¢‘æ ¼å¼é”™è¯¯: {type(audio)}, å†…å®¹: {audio}")
                return history + [("<audio controls style='display:none;'></audio>", "å½•éŸ³æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•")], history, None, ""
            
            # ä¿å­˜ä¸€ä¸ªæ°¸ä¹…å‰¯æœ¬ç”¨äºå‰ç«¯æ’­æ”¾
            timestamp = int(time.time())
            audio_filename = f"audio_input_{timestamp}.wav"
            audio_path = os.path.join("static", audio_filename)
            
            # ç¡®ä¿staticç›®å½•å­˜åœ¨
            os.makedirs("static", exist_ok=True)
            
            # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
            import shutil
            shutil.copy(temp_audio.name, audio_path)
            
            # è¯­éŸ³è¯†åˆ«
            message = AudioService.asr_recognize(temp_audio.name)
            os.unlink(temp_audio.name)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            
            if not message or message == "è¯­éŸ³è¯†åˆ«å¤±è´¥" or message == "è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥":
                return history + [(f"<audio src='/{audio_path}' controls style='display:none;'></audio>", "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")], history, None, ""
        except Exception as e:
            print(f"å¤„ç†å½•éŸ³æ—¶å‡ºé”™: {e}")
            return history + [("<audio controls style='display:none;'></audio>", f"å¤„ç†å½•éŸ³æ—¶å‡ºé”™: {str(e)}")], history, None, ""
    
    # å¦‚æœæ¶ˆæ¯ä¸ºç©ºï¼Œä¸å¤„ç†
    if not message or message.strip() == "":
        return history, history, None, ""
    
    # æ›´æ–°å†å²è®°å½•ï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    history_for_display = history.copy()
    
    # å¦‚æœæ˜¯è¯­éŸ³è¾“å…¥ï¼Œæ·»åŠ éŸ³é¢‘æ§ä»¶ï¼ˆä¸æ˜¾ç¤º[éŸ³é¢‘æ–‡ä»¶]æ ‡ç­¾ï¼‰
    if audio is not None:
        # åˆ›å»ºå¸¦æœ‰éŸ³é¢‘æ§ä»¶çš„æ¶ˆæ¯ï¼Œåªæ˜¾ç¤ºè¯†åˆ«å‡ºçš„æ–‡æœ¬å’Œéšè—çš„éŸ³é¢‘æ§ä»¶
        audio_message = f"{message} <audio src='/{audio_path}' controls style='display:none;'></audio>"
        history_for_display.append((audio_message, None))
    else:
        history_for_display.append((message, None))
    
    # åœ¨ç”¨æˆ·æ¶ˆæ¯åæ·»åŠ è‹±æ–‡å›å¤è¯·æ±‚ï¼ˆä¸æ˜¾ç¤ºåœ¨å‰ç«¯ï¼Œä½†ä¼ ç»™æ¨¡å‹ï¼‰
    message_with_english_request = message + " Please answer in English."
    
    # å‘é€èŠå¤©è¯·æ±‚
    chat_history = [(h[0], h[1]) for h in history if h[1] is not None]
    response = ChatService.send_chat_request(message_with_english_request, chat_history, lora_path, prompt_choice, promptFormat_choice)
    
    # è·å–å›å¤
    reply = response.get("reply", "Sorry, the server did not return a valid reply")
    
    # æ ¹æ®TTSé€‰æ‹©è¿›è¡Œè¯­éŸ³åˆæˆ
    if tts_choice == "Standard Voice":
        # ä½¿ç”¨æ ‡å‡†å¥³å£°é…ç½®
        audio_path = AudioService.tts_synthesize(reply)
    elif tts_choice == "Soft Female Voice":
        # ä½¿ç”¨æ¸©æŸ”å¥³å£°é…ç½®ï¼ˆåº¦ä¸«ä¸«éŸ³è‰²ï¼Œé™ä½è¯­é€Ÿï¼Œæé«˜éŸ³è°ƒï¼‰
        audio_path = AudioService.tts_synthesize(reply, spd=4, pit=6, per=4)
    elif tts_choice == "Energetic Male Voice":
        # ä½¿ç”¨æ´»åŠ›ç”·å£°é…ç½®ï¼ˆåº¦é€é¥éŸ³è‰²ï¼Œæé«˜è¯­é€Ÿå’ŒéŸ³è°ƒï¼‰
        audio_path = AudioService.tts_synthesize(reply, spd=6, pit=6, per=3)
    else:
        # é»˜è®¤ä½¿ç”¨æ ‡å‡†é…ç½®
        audio_path = AudioService.tts_synthesize(reply)
    
    # æ›´æ–°æ˜¾ç¤ºå†å²
    history_for_display[-1] = (message, reply)
    
    # è¿”å›æ›´æ–°åçš„å†å²ã€éŸ³é¢‘è·¯å¾„å’Œç©ºå­—ç¬¦ä¸²ï¼ˆæ¸…ç©ºè¾“å…¥æ¡†ï¼‰
    return history_for_display, chat_history + [(message, reply)], audio_path, ""

# å¤„ç†æ–‡ä»¶ä¸Šä¼ 
def handle_upload(file, history, lora_path, prompt_choice, promptFormat_choice, tts_choice):
    if file is None:
        return history, history
    
    # è¯­éŸ³è¯†åˆ«
    message = AudioService.asr_recognize(file.name)
    
    if not message or message == "è¯­éŸ³è¯†åˆ«å¤±è´¥" or message == "è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥":
        return history + [("<audio src='" + file.name + "' controls style='display:none;'></audio>", "Speech recognition failed, please try again")], history
    
    # æ›´æ–°å†å²è®°å½•ï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¸æ˜¾ç¤º[éŸ³é¢‘æ–‡ä»¶]æ ‡ç­¾ï¼‰
    history_for_display = history.copy()
    history_for_display.append((message, None))
    
    # åœ¨ç”¨æˆ·æ¶ˆæ¯åæ·»åŠ è‹±æ–‡å›å¤è¯·æ±‚ï¼ˆä¸æ˜¾ç¤ºåœ¨å‰ç«¯ï¼Œä½†ä¼ ç»™æ¨¡å‹ï¼‰
    message_with_english_request = message + " Please answer in English."
    
    # å‘é€èŠå¤©è¯·æ±‚
    chat_history = [(h[0], h[1]) for h in history if h[1] is not None]
    response = ChatService.send_chat_request(message_with_english_request, chat_history, lora_path, prompt_choice, promptFormat_choice)
    
    # è·å–å›å¤
    reply = response.get("reply", "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ²¡æœ‰è¿”å›æœ‰æ•ˆå›å¤")
    
    # æ ¹æ®TTSé€‰æ‹©è¿›è¡Œè¯­éŸ³åˆæˆ
    if tts_choice == "æ ‡å‡†è¯­éŸ³":
        # ä½¿ç”¨æ ‡å‡†å¥³å£°é…ç½®
        audio_path = AudioService.tts_synthesize(reply)
    elif tts_choice == "æ¸©æŸ”å¥³å£°":
        # ä½¿ç”¨æ¸©æŸ”å¥³å£°é…ç½®ï¼ˆåº¦ä¸«ä¸«éŸ³è‰²ï¼Œé™ä½è¯­é€Ÿï¼Œæé«˜éŸ³è°ƒï¼‰
        audio_path = AudioService.tts_synthesize(reply, spd=4, pit=6, per=4)
    elif tts_choice == "æ´»åŠ›ç”·å£°":
        # ä½¿ç”¨æ´»åŠ›ç”·å£°é…ç½®ï¼ˆåº¦é€é¥éŸ³è‰²ï¼Œæé«˜è¯­é€Ÿå’ŒéŸ³è°ƒï¼‰
        audio_path = AudioService.tts_synthesize(reply, spd=6, pit=6, per=3)
    else:
        # é»˜è®¤ä½¿ç”¨æ ‡å‡†é…ç½®
        audio_path = AudioService.tts_synthesize(reply)
    
    # æ›´æ–°å†å²è®°å½•ï¼ˆä¸æ˜¾ç¤º[éŸ³é¢‘æ–‡ä»¶]æ ‡ç­¾ï¼‰
    history_for_display[-1] = (message, reply)
    
    # è¿”å›æ›´æ–°åçš„å†å²ã€éŸ³é¢‘è·¯å¾„å’Œç©ºå­—ç¬¦ä¸²ï¼ˆæ¸…ç©ºè¾“å…¥æ¡†ï¼‰
    return history_for_display, chat_history + [(message, reply)], audio_path, ""

# å¯¼å…¥é…ç½®
from config import APP_TITLE, APP_SUBTITLE, APP_THEME, APP_PRIMARY_COLOR

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(theme=gr.themes.Soft(primary_hue=APP_PRIMARY_COLOR), css=".container { max-width: 800px; margin: auto; }") as demo:
        gr.Markdown(
            f"""# {APP_TITLE}
            {APP_SUBTITLE}
            """
        )
        
        with gr.Row():
            with gr.Column(scale=4):
                chatbot = gr.Chatbot(
                    [],
                    elem_id="chatbot",
                    height=500,
                    avatar_images=("https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f464.png", "https://cdn-icons-png.flaticon.com/512/4712/4712035.png"),
                )
                
                with gr.Row():
                    with gr.Column(scale=12):
                        msg = gr.Textbox(
                            show_label=False,
                            placeholder="Enter message...",
                            container=False
                        )
                    
                    with gr.Column(scale=1, min_width=50):
                        upload_btn = gr.UploadButton("â•", file_types=["audio/*"], size="sm")
                    
                    with gr.Column(scale=1, min_width=50):
                        submit_btn = gr.Button("Send", variant="primary", size="sm")
                        
                # æ·»åŠ JavaScriptä»£ç ï¼Œç”¨äºéŸ³é¢‘å½•åˆ¶æ§åˆ¶
                mic_js = """
                <script>
                document.addEventListener('DOMContentLoaded', function() {
                    // å½•éŸ³çŠ¶æ€æç¤º
                    const statusEl = document.getElementById('recording_status');
                    let isRecording = false;
                    let timer = null;
                    
                    // ç›‘å¬éŸ³é¢‘è¾“å…¥ç»„ä»¶çš„å˜åŒ–
                    const audioInput = document.getElementById('mic_input');
                    if (!audioInput) return; // ç¡®ä¿éŸ³é¢‘ç»„ä»¶å­˜åœ¨
                    
                    // ç›‘å¬å½•éŸ³æŒ‰é’®ç‚¹å‡»
                    const recordButtons = audioInput.querySelectorAll('.record, .stop');
                    recordButtons.forEach(button => {
                        button.addEventListener('click', function() {
                            // æ£€æµ‹æ˜¯å¦æ˜¯å¼€å§‹å½•éŸ³æŒ‰é’®
                            if (this.classList.contains('record')) {
                                isRecording = true;
                                // å¼€å§‹å½•éŸ³ï¼šæ›´æ–°è®¡æ—¶
                                let seconds = 0;
                                timer = setInterval(() => {
                                    const mins = Math.floor(seconds / 60).toString().padStart(2, '0');
                                    const secs = (seconds % 60).toString().padStart(2, '0');
                                    statusEl.innerHTML = `<span style="color: red;">Recording ${mins}:${secs}</span>`;
                                    seconds++;
                                }, 1000);
                            } else if (this.classList.contains('stop')) {
                                // åœæ­¢å½•éŸ³
                                isRecording = false;
                                clearInterval(timer);
                                statusEl.innerHTML = '';
                                
                                // ç­‰å¾…ä¸€å°æ®µæ—¶é—´åè‡ªåŠ¨æäº¤å½•éŸ³
                                setTimeout(() => {
                                    // æŸ¥æ‰¾æäº¤æŒ‰é’®å¹¶è§¦å‘ç‚¹å‡»
                                    const submitBtn = document.querySelector('button[variant="primary"]');
                                    if (submitBtn) {
                                        submitBtn.click();
                                    } else {
                                        // å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾SendæŒ‰é’®
                                        const allButtons = document.querySelectorAll('button');
                                        for (const btn of allButtons) {
                                            if (btn.textContent.includes('Send')) {
                                                btn.click();
                                                break;
                                            }
                                        }
                                    }
                                }, 1000);
                            }
                        });
                    });
                    }
                    
                        // è¯­éŸ³æ¶ˆæ¯æ’­æ”¾ä¼˜åŒ–
                        setInterval(() => {
                            const audioElements = document.querySelectorAll('#chatbot audio');
                            audioElements.forEach(audio => {
                                if (!audio.parentNode.classList.contains('audio-wrapped')) {
                                    const wrapper = document.createElement('div');
                                    wrapper.className = 'audio-wrapped';
                                    wrapper.style.marginTop = '8px';
                                    audio.parentNode.insertBefore(wrapper, audio);
                                    wrapper.appendChild(audio);
                                    // å¼ºåˆ¶æ˜¾ç¤ºéŸ³é¢‘æ§ä»¶
                                    audio.style.display = 'block';
                                }
                            });
                        }, 1000);
                    });
                    
                    // å®šæœŸæ£€æŸ¥å¹¶è®¾ç½®æ–°æ·»åŠ çš„è¯­éŸ³æ¶ˆæ¯
                    setInterval(function() {
                        try {
                            const messages = document.querySelectorAll('.message:not(.user)');
                            messages.forEach(function(message) {
                                if (!message.hasAttribute('data-audio-processed')) {
                                    const audioElements = message.querySelectorAll('audio');
                                    audioElements.forEach(function(audio) {
                                        if (audio.src) {
                                            // åˆ›å»ºè¯­éŸ³æ¡å…ƒç´ 
                                            const audioMessage = document.createElement('div');
                                            audioMessage.className = 'audio-message';
                                            audioMessage.setAttribute('data-audio-url', audio.src);
                                            audioMessage.innerHTML = `
                                                <div style="display: flex; align-items: center; background: #e6f7ff; padding: 5px 10px; border-radius: 15px; width: fit-content; cursor: pointer;">
                                                    <span style="margin-right: 5px;">ğŸ”Š</span>
                                                    <div style="width: 50px; height: 20px; background: url('data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMjAiPjxwYXRoIGQ9Ik0wLDEwIHE1LC04IDEwLDAgdDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCkiIGZpbGw9Im5vbmUiIHN0cm9rZT0iIzAwN2JmZiIgc3Ryb2tlLXdpZHRoPSIyIj48YW5pbWF0ZVRyYW5zZm9ybSBhdHRyaWJ1dGVOYW1lPSJkIiBhdHRyaWJ1dGVUeXBlPSJYTUwiIHR5cGU9InRyYW5zbGF0ZSIgdmFsdWVzPSJNMCwxMCBxNSwtOCAxMCwwIHQxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDApO00wLDEwIHE1LDggMTAsMCB0MTAsLTggMTAsOCAxMCwtOCAxMCw4IDEwLC04IDEwLDggMTAsLTggMTAsOCkiIGR1cj0iMC44cyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiLz48L3BhdGg+PC9zdmc+') center center no-repeat;"></div>
                                                </div>
                                            `;
                                            
                                            // å°†è¯­éŸ³æ¡æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                                            message.appendChild(audioMessage);
                                            message.setAttribute('data-audio-processed', 'true');
                                        }
                                    });
                                }
                            });
                        } catch (error) {
                            console.error('Failed to process voice message:', error);
                        }
                    }, 1000);
                });
                </script>
                """
                gr.HTML(mic_js)
                
                # è¯­éŸ³è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=1):
                        # è¯­éŸ³è¾“å…¥å¡ç‰‡ï¼Œå¯ç”¨GradioåŸç”Ÿå½•éŸ³åŠŸèƒ½ï¼Œåªæ˜¾ç¤ºå½•éŸ³é€‰é¡¹
                        # æ³¨æ„ï¼šç¡®ä¿è¿™ä¸ªå…ƒç´ IDä¸ºmic_inputï¼Œä¸JavaScriptä¸­çš„é€‰æ‹©å™¨åŒ¹é…
                        audio_input = gr.Audio(label="Voice Input", elem_id="mic_input", visible=True, autoplay=True, show_download_button=False, show_share_button=False, interactive=True, type="filepath", sources=["microphone"])
                        recording_status = gr.HTML("", elem_id="recording_status", visible=True)
                
                audio_output = gr.Audio(label="Voice Reply", visible=True, autoplay=True)
                
            # æ¨¡å‹å’Œæç¤ºé€‰æ‹©
            with gr.Column(scale=1):
                lora_path = gr.Radio(
                    ["estj", "infp", "base_1", "base_2"],
                    label="Model Selection",
                    value="estj"
                )
                
                prompt_choice = gr.Radio(
                    ["assist_estj", "assist_infp", "null"],
                    label="Prompt Selection",
                    value="assist_estj"
                )
                
                # æ ¼å¼é€‰æ‹©é»˜è®¤ä½¿ç”¨ordinaryä¸”éšè—å‰ç«¯æ˜¾ç¤º
                promptFormat_choice = gr.Radio(
                    ["ordinary", "custom"],
                    label="Format Selection",
                    value="ordinary",
                    visible=False
                )
                
                # å¢åŠ TTSé€‰æ‹©
                tts_choice = gr.Radio(
                    ["Standard Voice", "Soft Female Voice", "Energetic Male Voice"],
                    label="Voice Style Selection",
                    value="Standard Voice"
                )
                
                clear_btn = gr.Button("Clear Chat")
            
            # å­˜å‚¨èŠå¤©å†å²çš„çŠ¶æ€
            chat_history = gr.State([])
            
            # ç¡®ä¿éŸ³é¢‘è¾“å…¥ä¸èŠå¤©å‡½æ•°å…³è”ï¼ˆåœ¨å®šä¹‰æ‰€æœ‰å˜é‡åï¼‰
            audio_input.change(fn=handle_chat, inputs=[audio_input, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice], outputs=[chatbot, chat_history, audio_output, audio_input])
            
            # æ·»åŠ JavaScriptä»£ç ï¼Œç”¨äºæµè§ˆå™¨æœ¬åœ°TTS
            js_code = """
                function browserTTS(text) {
                    if ('speechSynthesis' in window) {
                        // åˆ›å»ºè¯­éŸ³åˆæˆå®ä¾‹
                        const utterance = new SpeechSynthesisUtterance(text);
                        // è®¾ç½®è¯­éŸ³å‚æ•°
                        utterance.rate = 1.0;  // è¯­é€Ÿ
                        utterance.pitch = 1.0; // Pitch
                        utterance.volume = 1.0; // Volume
                        // Get Chinese voice
                        const voices = window.speechSynthesis.getVoices();
                        const chineseVoice = voices.find(voice => voice.lang.includes('zh'));
                        if (chineseVoice) {
                            utterance.voice = chineseVoice;
                        }
                        // Play voice
                        window.speechSynthesis.speak(utterance);
                        return true;
                    }
                    return false;
                }
                
                // Listen for chat reply updates and add avatars
                document.addEventListener('DOMContentLoaded', function() {
                    // Regularly check for new chat messages
                    setInterval(function() {
                        // TTS processing
                        const ttsChoice = document.querySelector('input[name="tts_choice"]:checked');
                        if (ttsChoice && ttsChoice.value === "Browser Local TTS") {
                            const chatMessages = document.querySelectorAll('.message:not(.user)');
                            const lastMessage = chatMessages[chatMessages.length - 1];
                            if (lastMessage && !lastMessage.hasAttribute('data-tts-processed')) {
                                const messageText = lastMessage.textContent.trim();
                                if (messageText) {
                                    browserTTS(messageText);
                                    lastMessage.setAttribute('data-tts-processed', 'true');
                                }
                            }
                        }
                        
                        // Add avatars to all messages
                        addAvatarsToMessages();
                    }, 1000);
                    
                    // Function to add avatars
                    function addAvatarsToMessages() {
                        // Get all message elements
                        const userMessages = document.querySelectorAll('.message.user');
                        const botMessages = document.querySelectorAll('.message.bot');
                        
                        // ä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ å¤´åƒ
                        userMessages.forEach(msg => {
                            if (!msg.hasAttribute('data-avatar-added')) {
                                const avatar = document.createElement('div');
                                avatar.className = 'user-avatar';
                                avatar.style.cssText = 'position:absolute;left:-40px;top:0;width:35px;height:35px;background-image:url("https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f464.png");background-size:cover;border-radius:50%;';
                                
                                // ç¡®ä¿æ¶ˆæ¯å®¹å™¨æ˜¯ç›¸å¯¹å®šä½
                                msg.style.position = 'relative';
                                msg.style.marginLeft = '40px';
                                msg.style.marginBottom = '10px';
                                
                                // æ’å…¥å¤´åƒ
                                msg.insertBefore(avatar, msg.firstChild);
                                msg.setAttribute('data-avatar-added', 'true');
                            }
                        });
                        
                        // ä¸ºæœºå™¨äººæ¶ˆæ¯æ·»åŠ å¤´åƒ
                        botMessages.forEach(msg => {
                            if (!msg.hasAttribute('data-avatar-added')) {
                                const avatar = document.createElement('div');
                                avatar.className = 'bot-avatar';
                                avatar.style.cssText = 'position:absolute;left:-40px;top:0;width:35px;height:35px;background-image:url("https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f916.png");background-size:cover;border-radius:50%;';
                                
                                // ç¡®ä¿æ¶ˆæ¯å®¹å™¨æ˜¯ç›¸å¯¹å®šä½
                                msg.style.position = 'relative';
                                msg.style.marginLeft = '40px';
                                msg.style.marginBottom = '10px';
                                
                                // æ’å…¥å¤´åƒ
                                msg.insertBefore(avatar, msg.firstChild);
                                msg.setAttribute('data-avatar-added', 'true');
                            }
                        });
                    }
                });
                """
            gr.HTML("<script>" + js_code + "</script>", visible=False)
        
        # äº‹ä»¶å¤„ç†
        submit_btn.click(
            handle_chat,
            [msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice],
            [chatbot, chat_history, audio_output, msg],
            api_name="submit"
        )
        
        msg.submit(
            handle_chat,
            [msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice],
            [chatbot, chat_history, audio_output, msg]
        )
        
        # éŸ³é¢‘è¾“å…¥å¤„ç†ï¼ˆå½•éŸ³å®Œæˆåè‡ªåŠ¨å¤„ç†ï¼‰
        audio_input.change(
            fn=handle_audio,
            inputs=[audio_input, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice],
            outputs=[chatbot, chat_history, audio_output, msg],
            api_name="audio"
        )
        
        # éº¦å…‹é£éŸ³é¢‘è¾“å…¥å¤„ç†ï¼ˆå½•éŸ³åœæ­¢åè‡ªåŠ¨å¤„ç†ï¼‰
        audio_input.stop_recording(
            fn=handle_chat,
            # ç¡®ä¿å‚æ•°é¡ºåºä¸handle_chatå‡½æ•°å®šä¹‰ä¸€è‡´
            inputs=[msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, audio_input],
            outputs=[chatbot, chat_history, audio_output, msg],
            api_name="mic_recording"
        )
        
        upload_btn.upload(
            handle_upload,
            [upload_btn, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice],
            [chatbot, chat_history, audio_output, msg],
            api_name="upload"
        )
        
        # éŸ³é¢‘è¾“å…¥å·²ç»åœ¨ä¸Šé¢çš„audio_input.changeäº‹ä»¶ä¸­å¤„ç†
        
        clear_btn.click(
            lambda: ([], []),
            None,
            [chatbot, chat_history],
            api_name="clear"
        )
        
        # è‡ªå®šä¹‰CSS
        gr.Markdown("""
        <style>
        .gradio-container {
            font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        }
        
        #chatbot {
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            padding-left: 10px; /* ä¸ºå¤´åƒç•™å‡ºç©ºé—´ */
        }
        
        /* è°ƒæ•´èŠå¤©å®¹å™¨å†…éƒ¨å¸ƒå±€ */
        .chatbot {
            padding: 15px;
        }
        
        /* ç¡®ä¿æ¶ˆæ¯å®¹å™¨æœ‰è¶³å¤Ÿç©ºé—´æ˜¾ç¤ºå¤´åƒ */
        .message-wrap {
            position: relative;
            padding-left: 10px;
        }
        
        /* æ·»åŠ å¤´åƒå’Œæ°”æ³¡æ ·å¼ - ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨ */
        #chatbot .user {
            background-color: #f0f4f9;
            border-radius: 10px;
            padding: 10px 15px;
            margin-bottom: 10px;
            margin-left: 40px !important;
            position: relative !important;
        }
        
        #chatbot .user::before {
            content: '' !important;
            position: absolute !important;
            left: -40px !important;
            top: 0 !important;
            width: 35px !important;
            height: 35px !important;
            background-image: url('https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f464.png') !important;
            background-size: cover !important;
            border-radius: 50% !important;
            z-index: 100 !important;
        }
        
        #chatbot .bot {
            background-color: #e6f7ff;
            border-radius: 10px;
            padding: 10px 15px;
            margin-bottom: 10px;
            margin-left: 40px !important;
            position: relative !important;
        }
        
        #chatbot .bot::before {
            content: '' !important;
            position: absolute !important;
            left: -40px !important;
            top: 0 !important;
            width: 35px !important;
            height: 35px !important;
            background-image: url('https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f916.png') !important;
            background-size: cover !important;
            border-radius: 50% !important;
            z-index: 100 !important;
        }
        
        /* ä¼˜åŒ–éŸ³é¢‘è¾“å…¥ç»„ä»¶æ˜¾ç¤º */
        #mic_input {
            margin-top: 10px;
            border: none;
        }
        
        /* éšè—GradioåŸç”Ÿçš„å½•éŸ³æŒ‰é’®ï¼ˆä»…ä¿ç•™éŸ³é¢‘æ’­æ”¾æ§ä»¶ï¼‰ */
        #mic_input .controls > button:not(.play-button) {
            display: none !important;
        }
        
        /* ç¡®ä¿å½•éŸ³æŒ‰é’®å¯¹ç”¨æˆ·ä¸å¯è§ä½†JSå¯è®¿é—® */
        #mic_input .record, #mic_input .stop {
            opacity: 0 !important;
            position: absolute !important;
            pointer-events: all !important; /* å…è®¸JSç‚¹å‡»äº‹ä»¶ */
            width: 1px !important;
            height: 1px !important;
            overflow: hidden !important;
            z-index: -1 !important; /* ç¡®ä¿åœ¨è§†è§‰ä¸Šéšè— */
        }
        
        /* ç¾åŒ–éº¦å…‹é£æŒ‰é’® */
        #mic_button {
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 20px;
            padding: 8px 16px;
            cursor: pointer;
            width: 100%;
            transition: all 0.3s ease;
        }
        
        #mic_button:hover {
            transform: scale(1.05);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        #recording_status {
            margin-top: 5px;
            text-align: center;
            font-size: 12px;
        }
        
        .audio-message {
            margin-top: 10px;
            cursor: pointer;
        }
        
        .audio-message:hover {
            opacity: 0.8;
        }
        
        #mic_button {
            transition: all 0.3s ease;
        }
        
        #mic_button:hover {
            transform: scale(1.1);
        }
        </style>
        """)
    
    return demo

# ä¸»å‡½æ•°
def main():
    import argparse
    
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='å¯åŠ¨MBTIèŠå¤©åº”ç”¨')
    parser.add_argument('--server_port', type=int, default=8003, help='æœåŠ¡å™¨ç«¯å£å·')
    args = parser.parse_args()
    
    demo = create_interface()
    # æ·»åŠ é™æ€æ–‡ä»¶ç›®å½•é…ç½®ï¼Œç”¨äºè®¿é—®å½•éŸ³æ–‡ä»¶
    demo.launch(share=True, server_name="0.0.0.0", server_port=args.server_port, favicon_path=None, allowed_paths=["static"])

if __name__ == "__main__":
    main()