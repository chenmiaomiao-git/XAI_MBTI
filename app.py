
# ============================================================================
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
# ============================================================================

# å¯¼å…¥Gradioåº“ï¼Œç”¨äºåˆ›å»ºWebç•Œé¢
import gradio as gr
# å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
import os
# å¯¼å…¥ä¸´æ—¶æ–‡ä»¶å¤„ç†æ¨¡å—ï¼Œç”¨äºå¤„ç†éŸ³é¢‘æ–‡ä»¶
import tempfile
# å¯¼å…¥æ•°å€¼è®¡ç®—åº“
import numpy as np
# å¯¼å…¥éŸ³é¢‘æ–‡ä»¶å¤„ç†åº“
import soundfile as sf
# å¯¼å…¥æ—¥æœŸæ—¶é—´å¤„ç†æ¨¡å—
from datetime import datetime
# å¯¼å…¥ç±»å‹æ³¨è§£æ”¯æŒ
from typing import List, Tuple, Optional, Dict, Any
# å¯¼å…¥æ—¶é—´å¤„ç†æ¨¡å—
import time

# éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥å‡½æ•°
def check_audio_file(file_path):
    """Check if audio file is valid and return detailed information"""
    if not file_path:
        return {"valid": False, "error": "File path is empty"}
    
    try:
        if not os.path.exists(file_path):
            return {"valid": False, "error": "File does not exist", "path": file_path}
        
        file_size = os.path.getsize(file_path)
        if file_size == 0:
            return {"valid": False, "error": "File size is 0", "path": file_path, "size": 0}
        
        # Try to read file header to check if it's a valid MP3 file
        with open(file_path, "rb") as f:
            header = f.read(4)
            # MP3æ–‡ä»¶å¯èƒ½çš„å¤´éƒ¨æ ¼å¼ï¼š
            # - ID3æ ‡ç­¾å¼€å¤´
            # - MPEGå¸§å¤´å¼€å¤´ï¼ˆå„ç§å˜ä½“ï¼‰
            is_mp3 = (
                header.startswith(b"ID3") or  # ID3 tag
                (header[0] == 0xff and (header[1] & 0xe0) == 0xe0)  # MPEG frame header: first 11 bits are all 1
            )
            
            if not is_mp3:
                # For TTS services like Volcano Engine, other valid audio formats may be returned
                # If file size is reasonable, we consider it valid
                if file_size > 1000:  # At least 1KB of audio data
                    print(f"Audio file validation: File header is not standard MP3 format but file size is reasonable, considered valid: {header.hex()}")
                    is_mp3 = True
                else:
                    return {"valid": False, "error": "Not a valid MP3 file", "path": file_path, "size": file_size, "header": header.hex()}
        
        return {"valid": True, "path": file_path, "size": file_size}
    except Exception as e:
        return {"valid": False, "error": str(e), "path": file_path}

# æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¯è®¿é—®æ€§å‡½æ•°
def test_audio_accessibility(file_path):
    """Test if audio file can be accessed by web server"""
    if not file_path or not os.path.exists(file_path):
        return {"accessible": False, "error": "File does not exist"}
    
    try:
        # Check file permissions
        file_stat = os.stat(file_path)
        file_mode = oct(file_stat.st_mode)[-3:]
        
        # Check if file is readable
        readable = os.access(file_path, os.R_OK)
        
        # Get absolute path of file
        abs_path = os.path.abspath(file_path)
        
        # Check if file is in temporary directory
        temp_dir = tempfile.gettempdir()
        in_temp_dir = abs_path.startswith(temp_dir)
        
        # Create a symbolic link to static directory to make file accessible via web (for testing only)
        static_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "static")
        if not os.path.exists(static_dir):
            os.makedirs(static_dir, exist_ok=True)
        
        link_path = os.path.join(static_dir, os.path.basename(file_path))
        try:
            # If link already exists, delete it first
            if os.path.exists(link_path):
                os.remove(link_path)
            # Create hard link (not symbolic link, as some systems may restrict symbolic links)
            os.link(file_path, link_path)
            link_created = True
        except Exception as e:
            link_created = False
            link_error = str(e)
        
        return {
            "accessible": readable,
            "path": file_path,
            "abs_path": abs_path,
            "permissions": file_mode,
            "in_temp_dir": in_temp_dir,
            "link_created": link_created,
            "link_path": link_path if link_created else None,
            "link_error": link_error if not link_created else None
        }
    except Exception as e:
        return {"accessible": False, "error": str(e), "path": file_path}

# å¯¼å…¥è‡ªå®šä¹‰æœåŠ¡æ¨¡å—
# AudioService: å¤„ç†è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆåŠŸèƒ½
from audio_service import AudioService
# ChatService: å¤„ç†èŠå¤©è¯·æ±‚å’Œå“åº”åŠŸèƒ½
from chat_service import ChatService

# æ³¨æ„ï¼šä»¥ä¸‹åŠŸèƒ½å·²ç»ç§»åŠ¨åˆ°ç›¸åº”çš„æœåŠ¡æ¨¡å—ä¸­
# - è¯­éŸ³è¯†åˆ«å’ŒåˆæˆåŠŸèƒ½å·²ç§»åŠ¨åˆ°AudioServiceæ¨¡å—
# - å‘é€èŠå¤©è¯·æ±‚åŠŸèƒ½å·²ç§»åŠ¨åˆ°ChatServiceæ¨¡å—

# ============================================================================
# éŸ³é¢‘å¤„ç†å’ŒèŠå¤©åŠŸèƒ½å‡½æ•°
# ============================================================================

# å¤„ç†éŸ³é¢‘è¾“å…¥å‡½æ•°
def handle_audio(audio, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice):
    """
    å¤„ç†ç”¨æˆ·çš„éŸ³é¢‘è¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºæ–‡æœ¬å¹¶ç”Ÿæˆå›å¤
    
    å‚æ•°:
        audio: ç”¨æˆ·çš„éŸ³é¢‘è¾“å…¥ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶è·¯å¾„æˆ–éŸ³é¢‘æ•°æ®å…ƒç»„
        history: å½“å‰çš„èŠå¤©å†å²è®°å½•
        lora_path: é€‰æ‹©çš„æ¨¡å‹è·¯å¾„
        prompt_choice: é€‰æ‹©çš„æç¤ºæ¨¡æ¿
        promptFormat_choice: é€‰æ‹©çš„æç¤ºæ ¼å¼
        tts_choice: é€‰æ‹©çš„è¯­éŸ³åˆæˆé£æ ¼
        reply_language_choice: é€‰æ‹©çš„å›å¤è¯­è¨€
        asr_language_choice: é€‰æ‹©çš„ASRè¯†åˆ«è¯­è¨€
        
    è¿”å›:
        chatbot_output: æ›´æ–°åçš„èŠå¤©ç•Œé¢å†å²
        chat_history_output: æ›´æ–°åçš„èŠå¤©å†å²æ•°æ®
        audio_output: ç”Ÿæˆçš„å›å¤éŸ³é¢‘è·¯å¾„
        "": æ¸…ç©ºè¾“å…¥æ¡†
    """
    # å¦‚æœæ˜¯éŸ³é¢‘è¾“å…¥ï¼Œå…ˆæ ¹æ®é€‰æ‹©çš„è¯­è¨€è¿›è¡Œè¯­éŸ³è¯†åˆ«
    asr_result = None
    if isinstance(audio, tuple):
        # å¦‚æœæ˜¯å½•éŸ³æ•°æ®ï¼Œä½¿ç”¨è¯­éŸ³è¯†åˆ«æœåŠ¡å°†å…¶è½¬æ¢ä¸ºæ–‡æœ¬
        audio_data, sample_rate = audio
        # æ ¹æ®é€‰æ‹©çš„ASRè¯­è¨€è®¾ç½®è¯­éŸ³è¯†åˆ«è¯­è¨€
        asr_result = AudioService.asr_recognize_from_numpy(audio_data, sample_rate, language=asr_language_choice)
        audio = None  # æ¸…ç©ºéŸ³é¢‘è¾“å…¥ï¼Œå› ä¸ºå·²ç»è½¬æ¢ä¸ºæ–‡æœ¬
    
    # è°ƒç”¨handle_chatå‡½æ•°å¤„ç†éŸ³é¢‘è¾“å…¥ï¼Œä¼ å…¥è¯†åˆ«ç»“æœä½œä¸ºæ–‡æœ¬æ¶ˆæ¯å‚æ•°
    chatbot_output, chat_history_output, audio_output, _ = handle_chat(asr_result, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice, audio)
    return chatbot_output, chat_history_output, audio_output, ""

# å¤„ç†èŠå¤©æäº¤å‡½æ•° - åº”ç”¨ç¨‹åºçš„æ ¸å¿ƒåŠŸèƒ½
def handle_chat(message, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice=None, audio=None):
    """
    å¤„ç†ç”¨æˆ·çš„èŠå¤©è¾“å…¥ï¼ˆæ–‡æœ¬æˆ–éŸ³é¢‘ï¼‰ï¼Œç”Ÿæˆå›å¤å¹¶åˆæˆè¯­éŸ³
    
    å‚æ•°:
        message: ç”¨æˆ·çš„æ–‡æœ¬æ¶ˆæ¯ï¼Œå¦‚æœæ˜¯éŸ³é¢‘è¾“å…¥åˆ™ä¸ºNone
        history: å½“å‰çš„èŠå¤©å†å²è®°å½•
        lora_path: é€‰æ‹©çš„æ¨¡å‹è·¯å¾„ï¼ˆå¦‚'estj', 'infp'ç­‰ï¼‰
        prompt_choice: é€‰æ‹©çš„æç¤ºæ¨¡æ¿ï¼ˆå¦‚'assist_estj', 'assist_infp'ç­‰ï¼‰
        promptFormat_choice: é€‰æ‹©çš„æç¤ºæ ¼å¼ï¼ˆå¦‚'ordinary', 'custom'ï¼‰
        tts_choice: é€‰æ‹©çš„è¯­éŸ³åˆæˆé£æ ¼ï¼ˆå¦‚'Standard Voice', 'Soft Female Voice'ç­‰ï¼‰
        reply_language_choice: é€‰æ‹©çš„å›å¤è¯­è¨€
        asr_language_choice: é€‰æ‹©çš„ASRè¯†åˆ«è¯­è¨€ï¼ˆå¯é€‰ï¼‰
        audio: å¯é€‰çš„éŸ³é¢‘è¾“å…¥ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶è·¯å¾„æˆ–éŸ³é¢‘æ•°æ®å…ƒç»„
        
    è¿”å›:
        history_for_display: æ›´æ–°åçš„èŠå¤©ç•Œé¢å†å²
        chat_history + [(message, reply)]: æ›´æ–°åçš„èŠå¤©å†å²æ•°æ®
        audio_path: ç”Ÿæˆçš„å›å¤éŸ³é¢‘è·¯å¾„
        "": æ¸…ç©ºè¾“å…¥æ¡†
    """
    audio_path = None  # åˆå§‹åŒ–éŸ³é¢‘è·¯å¾„å˜é‡
    
    # å¦‚æœå·²ç»æœ‰è¯†åˆ«ç»“æœï¼ˆä»handle_audioä¼ å…¥ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
    if message is not None:
        # ä½¿ç”¨å·²ç»è¯†åˆ«çš„æ–‡æœ¬ï¼Œä¸éœ€è¦é‡æ–°å¤„ç†éŸ³é¢‘
        pass
    # å¦‚æœæä¾›äº†éŸ³é¢‘ä½†æ²¡æœ‰è¯†åˆ«ç»“æœï¼Œè¿›è¡Œè¯­éŸ³è¯†åˆ«å¤„ç†
    elif audio is not None:
        try:
            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼å¹¶è¿›è¡Œç›¸åº”å¤„ç†
            if isinstance(audio, str):
                # å¦‚æœéŸ³é¢‘æ˜¯å­—ç¬¦ä¸²è·¯å¾„ï¼ŒéªŒè¯å®ƒæ˜¯æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                if not os.path.isfile(audio):
                    print(f"Invalid audio file path: {audio}")
                    return history + [("<audio controls style='display:none;'></audio>", "Invalid audio file")], history, None, ""
                audio_file_path = audio
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºåç»­å¤„ç†
                temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
                import shutil
                shutil.copy(audio_file_path, temp_audio.name)
                temp_audio.close()
            elif isinstance(audio, tuple) and len(audio) >= 2:
                # å¦‚æœéŸ³é¢‘æ˜¯å…ƒç»„æ ¼å¼(é‡‡æ ·ç‡, æ•°æ®)ï¼Œä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                sf.write(temp_audio.name, audio[1], audio[0])  # å†™å…¥é‡‡æ ·ç‡å’ŒéŸ³é¢‘æ•°æ®
                temp_audio.close()
            else:
                # ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                print(f"Audio format error: {type(audio)}, content: {audio}")
                return history + [("<audio controls style='display:none;'></audio>", "Recording format error, please try again")], history, None, ""
            
            # ä¿å­˜ä¸€ä¸ªæ°¸ä¹…å‰¯æœ¬ç”¨äºå‰ç«¯æ’­æ”¾
            timestamp = int(time.time())  # ä½¿ç”¨æ—¶é—´æˆ³ç¡®ä¿æ–‡ä»¶åå”¯ä¸€
            audio_filename = f"audio_input_{timestamp}.wav"
            audio_path = os.path.join("static", audio_filename)
            
            # ç¡®ä¿staticç›®å½•å­˜åœ¨ï¼Œç”¨äºå­˜å‚¨éŸ³é¢‘æ–‡ä»¶
            os.makedirs("static", exist_ok=True)
            
            # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°é™æ€ç›®å½•
            import shutil
            shutil.copy(temp_audio.name, audio_path)
            
            # è°ƒç”¨è¯­éŸ³è¯†åˆ«æœåŠ¡å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œä½¿ç”¨ASRè¯­è¨€é€‰æ‹©
            asr_lang = asr_language_choice if asr_language_choice else reply_language_choice
            message = AudioService.asr_recognize(temp_audio.name, language=asr_lang)
            os.unlink(temp_audio.name)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œé‡Šæ”¾ç©ºé—´
            
            # æ£€æŸ¥è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
            # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„é”™è¯¯è¿”å›å€¼
            error_messages = [
                "Speech recognition failed", 
                "Speech recognition request failed", 
                "Speech recognition request timeout",
                "Speech recognition network request failed",
                "Audio format conversion failed",
                "Failed to read audio file",
                "Audio data processing failed",
                "Unable to get Baidu access token"
            ]
            
            if not message or message in error_messages:
                # ç¡®ä¿audio_pathå·²å®šä¹‰ï¼Œå¦‚æœæœªå®šä¹‰åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
                audio_display = f"<audio src='/{audio_path}' controls style='display:none;'></audio>" if audio_path else "<audio controls style='display:none;'></audio>"
                error_msg = message if message else "Speech recognition failed"
                return history + [(audio_display, f"{error_msg}, please try again")], history, None, ""
        except Exception as e:
            # æ•è·å¹¶å¤„ç†éŸ³é¢‘å¤„ç†è¿‡ç¨‹ä¸­çš„ä»»ä½•å¼‚å¸¸
            print(f"Error processing recording: {e}")
            # ç¡®ä¿audio_pathå·²å®šä¹‰ï¼Œå¦‚æœæœªå®šä¹‰åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            audio_display = f"<audio src='/{audio_path}' controls style='display:none;'></audio>" if audio_path else "<audio controls style='display:none;'></audio>"
            return history + [(audio_display, f"Error processing recording: {str(e)}")], history, None, ""
    
    # å¦‚æœæ¶ˆæ¯ä¸ºç©ºï¼Œä¸è¿›è¡Œå¤„ç†ç›´æ¥è¿”å›
    if not message or message.strip() == "":
        return history, history, None, ""
    
    # åˆ›å»ºå†å²è®°å½•çš„å‰¯æœ¬ç”¨äºæ˜¾ç¤º
    history_for_display = history.copy()
    
    # æ ¹æ®è¾“å…¥ç±»å‹æ›´æ–°å†å²è®°å½•
    if audio is not None and audio_path is not None:
        # å¦‚æœæ˜¯è¯­éŸ³è¾“å…¥ï¼Œæ·»åŠ å¸¦æœ‰éšè—éŸ³é¢‘æ§ä»¶çš„æ¶ˆæ¯
        audio_message = f"{message} <audio src='/{audio_path}' controls style='display:none;'></audio>"
        history_for_display.append((audio_message, None))
    else:
        # å¦‚æœæ˜¯æ–‡æœ¬è¾“å…¥ï¼Œç›´æ¥æ·»åŠ æ¶ˆæ¯
        history_for_display.append((message, None))
    
    # æ ¹æ®é€‰æ‹©çš„å›å¤è¯­è¨€æ·»åŠ ç›¸åº”çš„è¯·æ±‚ï¼ˆä¸æ˜¾ç¤ºåœ¨å‰ç«¯ï¼Œä½†ä¼ ç»™æ¨¡å‹ï¼‰
    if reply_language_choice == "Chinese":
        message_with_language_request = message + " "
    elif reply_language_choice == "English":
        message_with_language_request = message + " Please answer in English"
    elif reply_language_choice == "Japanese":
        message_with_language_request = message + " æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„"
    else:
        # é»˜è®¤ä½¿ç”¨è‹±æ–‡
        message_with_language_request = message + " Please answer in English"
    
    # å‡†å¤‡èŠå¤©å†å²æ•°æ®ï¼Œè¿‡æ»¤æ‰æ²¡æœ‰å›å¤çš„æ¶ˆæ¯
    chat_history = [(h[0], h[1]) for h in history if h[1] is not None]
    
    # è°ƒç”¨èŠå¤©æœåŠ¡å‘é€è¯·æ±‚å¹¶è·å–å›å¤
    response = ChatService.send_chat_request(message_with_language_request, chat_history, lora_path, prompt_choice, promptFormat_choice)
    
    # ä»å“åº”ä¸­è·å–å›å¤æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤é”™è¯¯æ¶ˆæ¯
    reply = response.get("reply", "Sorry, the server did not return a valid reply")
    
    # æ ¹æ®é€‰æ‹©çš„TTSé£æ ¼è¿›è¡Œè¯­éŸ³åˆæˆ
    print(f"Audio playback debug: Starting speech synthesis, TTS choice = {tts_choice}, reply language = {reply_language_choice}")
    print(f"Audio playback debug: Reply text length = {len(reply)}")
    
    # ä¸­æ–‡è¯­è¨€ä½¿ç”¨ç™¾åº¦äº‘TTSï¼Œå…¶ä»–è¯­è¨€ä½¿ç”¨ç«å±±å¼•æ“TTS
    if reply_language_choice == "Chinese":
        if tts_choice == "Soft Female Voice - Cancan (Normal)":
            # ä¸­æ–‡-ä½¿ç”¨ç™¾åº¦äº‘TTS - å¥³å£°ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using Baidu Cloud TTS - Female voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, language=reply_language_choice, 
                                                  spd=5, pit=5, per=0)
        elif tts_choice == "Energetic Female Voice - Cancan (Fast)":
            # ä¸­æ–‡-ä½¿ç”¨ç™¾åº¦äº‘TTS - å¥³å£°ï¼Œå¿«é€Ÿè¯­é€Ÿå’Œé«˜éŸ³è°ƒ
            print("Audio playback debug: Using Baidu Cloud TTS - Female voice, fast speed and high pitch")
            audio_file_path = AudioService.tts_synthesize(reply, language=reply_language_choice, 
                                                  spd=7, pit=6, per=0)
        elif tts_choice == "Professional Foreign Voice - Stefan (Normal)":
            # ä¸­æ–‡-ä½¿ç”¨ç™¾åº¦äº‘TTS - ç”·å£°ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using Baidu Cloud TTS - Male voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, language=reply_language_choice, 
                                                  spd=5, pit=5, per=1)
        elif tts_choice == "Expressive Foreign Voice - Stefan (Fast)":
            # ä¸­æ–‡-ä½¿ç”¨ç™¾åº¦äº‘TTS - ç”·å£°ï¼Œå¿«é€Ÿè¯­é€Ÿå’Œé«˜éŸ³è°ƒ
            print("Audio playback debug: Using Baidu Cloud TTS - Male voice, fast speed and high pitch")
            audio_file_path = AudioService.tts_synthesize(reply, language=reply_language_choice, 
                                                  spd=7, pit=6, per=1)
        else:
            # ä¸­æ–‡-é»˜è®¤ä½¿ç”¨ç™¾åº¦äº‘TTS - å¥³å£°ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using default Baidu Cloud TTS - Female voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, language=reply_language_choice, 
                                                  spd=5, pit=5, per=0)
    else:
        # éä¸­æ–‡è¯­è¨€ä½¿ç”¨ç«å±±å¼•æ“TTS
        if tts_choice == "Soft Female Voice - Cancan (Normal)":
            # ä½¿ç”¨ç«å±±å¼•æ“TTS - ç¿ç¿éŸ³è‰²ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using Volcano Engine TTS - Cancan voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice, 
                                                  voice_type="BV700_streaming", speed=1.0, pitch=1.0)
        elif tts_choice == "Energetic Female Voice - Cancan (Fast)":
            # ä½¿ç”¨ç«å±±å¼•æ“TTS - ç¿ç¿éŸ³è‰²ï¼Œå¿«é€Ÿè¯­é€Ÿå’Œé«˜éŸ³è°ƒ
            print("Audio playback debug: Using Volcano Engine TTS - Cancan voice, fast speed and high pitch")
            audio_file_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice, 
                                                  voice_type="BV700_streaming", speed=1.3, pitch=1.2)
        elif tts_choice == "Professional Foreign Voice - Stefan (Normal)":
            # ä½¿ç”¨ç«å±±å¼•æ“TTS - StefanéŸ³è‰²ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using Volcano Engine TTS - Stefan voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice, 
                                                  voice_type="BV702_streaming", speed=1.0, pitch=1.0)
        elif tts_choice == "Expressive Foreign Voice - Stefan (Fast)":
            # ä½¿ç”¨ç«å±±å¼•æ“TTS - StefanéŸ³è‰²ï¼Œå¿«é€Ÿè¯­é€Ÿå’Œé«˜éŸ³è°ƒ
            print("Audio playback debug: Using Volcano Engine TTS - Stefan voice, fast speed and high pitch")
            audio_file_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice, 
                                                  voice_type="BV702_streaming", speed=1.3, pitch=1.2)
        else:
            # é»˜è®¤ä½¿ç”¨ç«å±±å¼•æ“TTS - ç¿ç¿éŸ³è‰²ï¼Œæ ‡å‡†è¯­é€Ÿå’ŒéŸ³è°ƒ
            print("Audio playback debug: Using default Volcano Engine TTS - Cancan voice, standard speed and pitch")
            audio_file_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice, 
                                                  voice_type="BV700_streaming", speed=1.0, pitch=1.0)
    
    # å°†æ–‡ä»¶è·¯å¾„èµ‹å€¼ç»™audio_pathå˜é‡ï¼Œä¿æŒä¸åç»­ä»£ç å…¼å®¹
    audio_path = audio_file_path
    
    # æ›´æ–°æ˜¾ç¤ºå†å²ï¼Œå°†æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸AIå›å¤é…å¯¹
    history_for_display[-1] = (message, reply)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨é™æ€ç›®å½•ä¸­ï¼Œå¦‚æœä¸æ˜¯ï¼Œåˆ™å¤åˆ¶åˆ°é™æ€ç›®å½•
    static_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "static")
    if not os.path.exists(static_dir):
        os.makedirs(static_dir, exist_ok=True)
    
    # ç›´æ¥ä½¿ç”¨TTSè¿”å›çš„éŸ³é¢‘æ–‡ä»¶
    if audio_path and os.path.exists(audio_path):
        try:
            # è·å–æ–‡ä»¶å
            filename = os.path.basename(audio_path)
            # æ„å»ºé™æ€ç›®å½•ä¸­çš„ç›®æ ‡è·¯å¾„
            static_audio_path = os.path.join(static_dir, filename)
            
            # å¦‚æœæ–‡ä»¶ä¸åœ¨é™æ€ç›®å½•ä¸­ï¼Œå¤åˆ¶åˆ°é™æ€ç›®å½•
            if audio_path != static_audio_path:
                import shutil
                shutil.copy2(audio_path, static_audio_path)
            
            # æ„å»ºç›¸å¯¹URLè·¯å¾„
            relative_path = os.path.join("static", filename)
            
            # ä¸åœ¨å¯¹è¯æ¡†ä¸­æ·»åŠ éŸ³é¢‘æ ‡ç­¾ï¼Œåªè¿”å›éŸ³é¢‘è·¯å¾„ä¾›ä¸“é—¨çš„å¡ç‰‡æ’­æ”¾
            history_for_display[-1] = (history_for_display[-1][0], reply)
            
            # è¿”å›ç»“æœï¼Œä½¿ç”¨ç»å¯¹æ–‡ä»¶è·¯å¾„è€ŒéURLè·¯å¾„
            audio_output_value = static_audio_path
            return history_for_display, chat_history + [(message, reply)], audio_output_value, ""
        except Exception as e:
            print(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›æ²¡æœ‰éŸ³é¢‘çš„ç»“æœ
    return history_for_display, chat_history + [(message, reply)], None, ""

# å¤„ç†æ–‡ä»¶ä¸Šä¼ å‡½æ•°
def handle_upload(file, history, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice):
    """
    Handle user uploaded audio files, convert them to text and generate replies
    
    Parameters:
        file: User uploaded audio file object
        history: Current chat history
        lora_path: Selected model path
        prompt_choice: Selected prompt template
        promptFormat_choice: Selected prompt format
        tts_choice: Selected TTS style
        reply_language_choice: Selected reply language
        asr_language_choice: Selected ASR recognition language
        
    Returns:
        history_for_display: Updated chat interface history
        chat_history + [(message, reply)]: Updated chat history data
        audio_path: Generated reply audio path
        "": Clear input box
    """
    # Check if file is empty
    if file is None:
        return history, history
    
    # Call speech recognition service to convert uploaded audio file to text, using ASR language selection
    message = AudioService.asr_recognize(file.name, language=asr_language_choice)
    
    # Check speech recognition result, return error message if failed
    if not message or message == "Speech recognition failed" or message == "Speech recognition request failed" or message == "Unable to get Baidu access token":
        return history + [("<audio src='" + file.name + "' controls style='display:none;'></audio>", "Speech recognition failed, please try again")], history
    
    # Create a copy of history for display
    history_for_display = history.copy()
    # Add user message to history
    history_for_display.append((message, None))
    
    # Add corresponding request based on selected reply language (not displayed in frontend, but passed to model)
    if reply_language_choice == "Chinese":
        message_with_language_request = message + " è¯·ç”¨ä¸­æ–‡å›ç­”"
    elif reply_language_choice == "English":
        message_with_language_request = message + " Please answer in English"
    elif reply_language_choice == "Japanese":
        message_with_language_request = message + " æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„"
    elif reply_language_choice == "French":
        message_with_language_request = message + " Veuillez rÃ©pondre en franÃ§ais"
    else:
        # Default to English
        message_with_language_request = message + " Please answer in English"
    
    # Prepare chat history data, filter out messages without replies
    chat_history = [(h[0], h[1]) for h in history if h[1] is not None]
    # Call chat service to send request and get reply
    response = ChatService.send_chat_request(message_with_language_request, chat_history, lora_path, prompt_choice, promptFormat_choice)
    
    # Get reply text from response, use default error message if none
    reply = response.get("reply", "Sorry, the server did not return a valid reply")
    
    # æ ¹æ®é€‰æ‹©çš„TTSé£æ ¼è¿›è¡Œè¯­éŸ³åˆæˆ
    if tts_choice == "Standard Voice":
        # Use standard female voice configuration
        audio_path = AudioService.tts_synthesize(reply, language=reply_language_choice)
    elif tts_choice == "Gentle Female Voice":
        # Use gentle female voice configuration (DuYaYa voice, lower speed, higher pitch)
        audio_path = AudioService.tts_synthesize(reply, spd=4, pit=6, per=4, language=reply_language_choice)
    elif tts_choice == "Energetic Male Voice":
        # Use energetic male voice configuration (DuXiaoyao voice, higher speed and pitch)
        audio_path = AudioService.tts_synthesize(reply, spd=6, pit=6, per=3, language=reply_language_choice)
    elif tts_choice == "Volcano Engine TTS":
        # Use Volcano Engine TTS
        audio_path = AudioService.tts_synthesize(reply, tts_engine="volcano", language=reply_language_choice)
    else:
        # Default to standard configuration
        audio_path = AudioService.tts_synthesize(reply, language=reply_language_choice)
    
    # Update display history, pair the last user message with AI reply
    history_for_display[-1] = (message, reply)
    
    # Process audio file, convert to numpy format for Gradio use
    audio_output_value = None
    if audio_path and os.path.exists(audio_path):
        try:
            import soundfile as sf
            import numpy as np
            data, samplerate = sf.read(audio_path)
            # Ensure data type is float32 and within [-1, 1] range
            if data.dtype != np.float32:
                data = data.astype(np.float32)
            # If data exceeds range, normalize
            if np.max(np.abs(data)) > 1.0:
                data = data / np.max(np.abs(data))
            print(f"Audio playback debug: handle_upload successfully read audio file, sample rate = {samplerate}, shape = {data.shape}, data type = {data.dtype}")
            audio_output_value = (int(samplerate), data)
        except Exception as e:
            print(f"éŸ³é¢‘æ’­æ”¾è°ƒè¯•: handle_upload failed to read audio file - {e}")
            try:
                from pydub import AudioSegment
                import numpy as np
                audio = AudioSegment.from_file(audio_path, format="mp3")
                # Convert to numpy array
                samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
                # If stereo, take one channel
                if audio.channels == 2:
                    samples = samples.reshape((-1, 2))[:, 0]
                # Normalize to [-1, 1] range
                if audio.sample_width == 2:  # 16-bit
                    samples = samples / 32768.0
                elif audio.sample_width == 4:  # 32-bit
                    samples = samples / 2147483648.0
                else:
                    samples = samples / np.max(np.abs(samples)) if np.max(np.abs(samples)) > 0 else samples
                audio_output_value = (int(audio.frame_rate), samples)
                print(f"éŸ³é¢‘æ’­æ”¾è°ƒè¯•: handle_uploadä½¿ç”¨pydubæˆåŠŸè¯»å–éŸ³é¢‘ï¼Œæ•°æ®ç±»å‹ = {samples.dtype}")
            except Exception as e2:
                print(f"éŸ³é¢‘æ’­æ”¾è°ƒè¯•: handle_uploadæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ - {e2}")
                import numpy as np
                audio_output_value = (16000, np.zeros(1000, dtype=np.int16))
    else:
        print(f"éŸ³é¢‘æ’­æ”¾è°ƒè¯•: handle_uploadéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        import numpy as np
        audio_output_value = (16000, np.zeros(1000, dtype=np.int16))
    
    # è¿”å›æ›´æ–°åçš„å†å²ã€èŠå¤©è®°å½•ã€éŸ³é¢‘æ•°æ®å’Œç©ºå­—ç¬¦ä¸²ï¼ˆæ¸…ç©ºè¾“å…¥æ¡†ï¼‰
    return history_for_display, chat_history + [(message, reply)], audio_output_value, ""

# ============================================================================
# UIç•Œé¢åˆ›å»ºéƒ¨åˆ†
# ============================================================================

# å¯¼å…¥åº”ç”¨ç¨‹åºé…ç½®
from config import APP_TITLE, APP_SUBTITLE, APP_THEME, APP_PRIMARY_COLOR

# åˆ›å»ºGradioç•Œé¢å‡½æ•°
def create_interface():
    """
    åˆ›å»ºåº”ç”¨ç¨‹åºçš„Gradio Webç•Œé¢
    
    é…ç½®æ•´ä¸ªåº”ç”¨çš„UIå¸ƒå±€ã€ç»„ä»¶å’Œäº‹ä»¶å¤„ç†
    
    è¿”å›:
        demo: é…ç½®å¥½çš„Gradio Blocksç•Œé¢å¯¹è±¡
    """
    # ä½¿ç”¨Gradio Blocksåˆ›å»ºè‡ªå®šä¹‰ç•Œé¢ï¼Œè®¾ç½®ä¸»é¢˜å’ŒCSSæ ·å¼
    with gr.Blocks(theme=gr.themes.Soft(primary_hue=APP_PRIMARY_COLOR), css=".container { max-width: 800px; margin: auto; }") as demo:
        # æ·»åŠ åº”ç”¨æ ‡é¢˜å’Œå‰¯æ ‡é¢˜
        gr.Markdown(
            f"""# {APP_TITLE}
            {APP_SUBTITLE}
            """
        )
        
        # åˆ›å»ºä¸»ç•Œé¢å¸ƒå±€ï¼Œä½¿ç”¨è¡Œå’Œåˆ—ç»„ç»‡ç»„ä»¶
        with gr.Row():
            # å·¦ä¾§ä¸»è¦èŠå¤©åŒºåŸŸï¼ˆå 4/5å®½åº¦ï¼‰
            with gr.Column(scale=4):
                # èŠå¤©æœºå™¨äººç»„ä»¶ï¼Œç”¨äºæ˜¾ç¤ºå¯¹è¯å†å²
                chatbot = gr.Chatbot(
                    [],  # åˆå§‹ä¸ºç©ºåˆ—è¡¨
                    elem_id="chatbot",  # HTMLå…ƒç´ IDï¼Œç”¨äºCSSå’ŒJavaScripté€‰æ‹©
                    height=500,  # è®¾ç½®é«˜åº¦
                    avatar_images=None,  # ç§»é™¤å¤´åƒå›¾ç‰‡ï¼Œä½¿ç”¨CSSè‡ªå®šä¹‰å¤´åƒ
                )
                
                # æ¶ˆæ¯è¾“å…¥åŒºåŸŸå¸ƒå±€
                with gr.Row():
                    # æ–‡æœ¬è¾“å…¥æ¡†ï¼ˆå å¤§éƒ¨åˆ†å®½åº¦ï¼‰
                    with gr.Column(scale=12):
                        msg = gr.Textbox(
                            show_label=False,  # ä¸æ˜¾ç¤ºæ ‡ç­¾
                            placeholder="Enter message...",  # å ä½æ–‡æœ¬
                            container=False  # ä¸ä½¿ç”¨å®¹å™¨æ ·å¼
                        )
                    
                    # ä¸Šä¼ æŒ‰é’®ï¼ˆå°åˆ—ï¼Œå›ºå®šå®½åº¦ï¼‰
                    with gr.Column(scale=1, min_width=50):
                        upload_btn = gr.UploadButton("â•", file_types=["audio/*"], size="lg")  # ä»…æ¥å—éŸ³é¢‘æ–‡ä»¶
                    
                    # å‘é€æŒ‰é’®ï¼ˆå°åˆ—ï¼Œå›ºå®šå®½åº¦ï¼‰
                    with gr.Column(scale=1, min_width=50):
                        submit_btn = gr.Button("Send", variant="primary", size="lg")  # ä¸»è¦æŒ‰é’®æ ·å¼
                        
                # æ·»åŠ JavaScriptä»£ç ï¼Œç”¨äºéŸ³é¢‘å½•åˆ¶æ§åˆ¶å’ŒUIå¢å¼º
                mic_js = """
                <script>
                document.addEventListener('DOMContentLoaded', function() {
                    // å½•éŸ³çŠ¶æ€æç¤ºå…ƒç´ ï¼Œç”¨äºæ˜¾ç¤ºå½•éŸ³æ—¶é—´
                    const statusEl = document.getElementById('recording_status');
                    let isRecording = false;
                    let timer = null;
                    
                    // è·å–éŸ³é¢‘è¾“å…¥ç»„ä»¶
                    const audioInput = document.getElementById('mic_input');
                    if (!audioInput) return; // ç¡®ä¿éŸ³é¢‘ç»„ä»¶å­˜åœ¨ï¼Œå¦åˆ™é€€å‡º
                    
                    // ç›‘å¬å½•éŸ³æŒ‰é’®ç‚¹å‡»äº‹ä»¶ï¼ˆå¼€å§‹å’Œåœæ­¢æŒ‰é’®ï¼‰
                    const recordButtons = audioInput.querySelectorAll('.record, .stop');
                    recordButtons.forEach(button => {
                        button.addEventListener('click', function() {
                            // æ£€æµ‹æ˜¯å¦æ˜¯å¼€å§‹å½•éŸ³æŒ‰é’®
                            if (this.classList.contains('record')) {
                                // å¼€å§‹å½•éŸ³çŠ¶æ€
                                isRecording = true;
                                // å¼€å§‹å½•éŸ³ï¼šåˆ›å»ºè®¡æ—¶å™¨æ˜¾ç¤ºå½•éŸ³æ—¶é•¿
                                let seconds = 0;
                                timer = setInterval(() => {
                                    // æ ¼å¼åŒ–åˆ†é’Ÿå’Œç§’é’Ÿï¼Œç¡®ä¿ä¸¤ä½æ•°æ˜¾ç¤º
                                    const mins = Math.floor(seconds / 60).toString().padStart(2, '0');
                                    const secs = (seconds % 60).toString().padStart(2, '0');
                                    // æ›´æ–°å½•éŸ³çŠ¶æ€æ˜¾ç¤º
                                    statusEl.innerHTML = `<span style="color: red;">Recording ${mins}:${secs}</span>`;
                                    seconds++;
                                }, 1000);
                            } else if (this.classList.contains('stop')) {
                                // åœæ­¢å½•éŸ³çŠ¶æ€
                                isRecording = false;
                                // æ¸…é™¤è®¡æ—¶å™¨å¹¶é‡ç½®çŠ¶æ€æ˜¾ç¤º
                                clearInterval(timer);
                                statusEl.innerHTML = '';
                                
                                // ç­‰å¾…ä¸€å°æ®µæ—¶é—´åè‡ªåŠ¨æäº¤å½•éŸ³ï¼ˆç»™ç³»ç»Ÿå¤„ç†éŸ³é¢‘çš„æ—¶é—´ï¼‰
                                setTimeout(() => {
                                    // æŸ¥æ‰¾æäº¤æŒ‰é’®å¹¶è§¦å‘ç‚¹å‡»äº‹ä»¶
                                    const submitBtn = document.querySelector('button[variant="primary"]');
                                    if (submitBtn) {
                                        submitBtn.click();
                                    } else {
                                        // å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾åŒ…å«'Send'æ–‡æœ¬çš„æŒ‰é’®
                                        const allButtons = document.querySelectorAll('button');
                                        for (const btn of allButtons) {
                                            if (btn.textContent.includes('Send')) {
                                                btn.click();
                                                break;
                                            }
                                        }
                                    }
                                }, 1000);
                            }
                        });
                    });
                    }
                    
                    // è¯­éŸ³æ¶ˆæ¯æ’­æ”¾ä¼˜åŒ–ï¼šå®šæœŸæ£€æŸ¥å¹¶ç¾åŒ–éŸ³é¢‘å…ƒç´ 
                    setInterval(() => {
                        // æŸ¥æ‰¾èŠå¤©åŒºåŸŸä¸­çš„æ‰€æœ‰éŸ³é¢‘å…ƒç´ 
                        const audioElements = document.querySelectorAll('#chatbot audio');
                        audioElements.forEach(audio => {
                            // ä¸ºæœªå¤„ç†çš„éŸ³é¢‘å…ƒç´ æ·»åŠ åŒ…è£…å™¨
                            if (!audio.parentNode.classList.contains('audio-wrapped')) {
                                // åˆ›å»ºåŒ…è£…divå¹¶è®¾ç½®æ ·å¼
                                const wrapper = document.createElement('div');
                                wrapper.className = 'audio-wrapped';
                                wrapper.style.marginTop = '8px';
                                // æ’å…¥åŒ…è£…å™¨å¹¶ç§»åŠ¨éŸ³é¢‘å…ƒç´ 
                                audio.parentNode.insertBefore(wrapper, audio);
                                wrapper.appendChild(audio);
                                // å¼ºåˆ¶æ˜¾ç¤ºéŸ³é¢‘æ§ä»¶ï¼ˆè¦†ç›–å¯èƒ½çš„éšè—è®¾ç½®ï¼‰
                                audio.style.display = 'block';
                            }
                        });
                    }, 1000);
                    });
                    
                    // å®šæœŸæ£€æŸ¥å¹¶è®¾ç½®æ–°æ·»åŠ çš„è¯­éŸ³æ¶ˆæ¯ï¼Œæ·»åŠ è‡ªå®šä¹‰UI
                    setInterval(function() {
                        try {
                            // æŸ¥æ‰¾æ‰€æœ‰éç”¨æˆ·æ¶ˆæ¯ï¼ˆæœºå™¨äººå›å¤ï¼‰
                            const messages = document.querySelectorAll('.message:not(.user)');
                            messages.forEach(function(message) {
                                // åªå¤„ç†å°šæœªå¤„ç†è¿‡çš„æ¶ˆæ¯
                                if (!message.hasAttribute('data-audio-processed')) {
                                    // æŸ¥æ‰¾æ¶ˆæ¯ä¸­çš„éŸ³é¢‘å…ƒç´ 
                                    const audioElements = message.querySelectorAll('audio');
                                    audioElements.forEach(function(audio) {
                                        // ç¡®ä¿éŸ³é¢‘æœ‰æº
                                        if (audio.src) {
                                            // åˆ›å»ºç¾åŒ–çš„è¯­éŸ³æ¡å…ƒç´ 
                                            const audioMessage = document.createElement('div');
                                            audioMessage.className = 'audio-message';
                                            audioMessage.setAttribute('data-audio-url', audio.src);
                                            // è®¾ç½®è¯­éŸ³æ¡çš„HTMLå†…å®¹ï¼ŒåŒ…å«æ³¢å½¢åŠ¨ç”»
                                            audioMessage.innerHTML = `
                                                <div style="display: flex; align-items: center; background: #e6f7ff; padding: 5px 10px; border-radius: 15px; width: fit-content; cursor: pointer;">
                                                    <span style="margin-right: 5px;">ğŸ”Š</span>
                                                    <div style="width: 50px; height: 20px; background: url('data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMjAiPjxwYXRoIGQ9Ik0wLDEwIHE1LC04IDEwLDAgdDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCkiIGZpbGw9Im5vbmUiIHN0cm9rZT0iIzAwN2JmZiIgc3Ryb2tlLXdpZHRoPSIyIj48YW5pbWF0ZVRyYW5zZm9ybSBhdHRyaWJ1dGVOYW1lPSJkIiBhdHRyaWJ1dGVUeXBlPSJYTUwiIHR5cGU9InRyYW5zbGF0ZSIgdmFsdWVzPSJNMCwxMCBxNSwtOCAxMCwwIHQxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDAgMTAsMCAxMCwwIDEwLDApO00wLDEwIHE1LDggMTAsMCB0MTAsLTggMTAsOCAxMCwtOCAxMCw4IDEwLC04IDEwLDggMTAsLTggMTAsOCkiIGR1cj0iMC44cyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiLz48L3BhdGg+PC9zdmc+') center center no-repeat;"></div>
                                                </div>
                                            `;
                                            
                                            // å°†è¯­éŸ³æ¡æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                                            message.appendChild(audioMessage);
                                            // æ ‡è®°æ¶ˆæ¯å·²å¤„ç†ï¼Œé¿å…é‡å¤å¤„ç†
                                            message.setAttribute('data-audio-processed', 'true');
                                        }
                                    });
                                }
                            });
                        } catch (error) {
                            // æ•è·å¹¶è®°å½•å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯
                            console.error('Failed to process voice message:', error);
                        }
                    }, 1000); // æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                });
                </script>
                """
                # æ’å…¥JavaScriptä»£ç åˆ°é¡µé¢
                gr.HTML(mic_js)
                
                # è¯­éŸ³è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=1):
                        # è¯­éŸ³è¾“å…¥ç»„ä»¶ï¼Œé…ç½®GradioåŸç”Ÿå½•éŸ³åŠŸèƒ½
                        # è®¾ç½®å…ƒç´ IDä¸ºmic_inputï¼Œä¸JavaScriptä¸­çš„é€‰æ‹©å™¨åŒ¹é…
                        # ä¸æ’­æ”¾å’Œæ˜¾ç¤ºå½•åˆ¶çš„éŸ³é¢‘ï¼Œå½•åˆ¶å’Œåœæ­¢æŒ‰é’®å§‹ç»ˆå¯è§
                        audio_input = gr.Audio(
                            label="Voice Input",  # ç»„ä»¶æ ‡ç­¾
                            elem_id="mic_input",  # HTMLå…ƒç´ ID
                            visible=True,  # å¯è§æ€§
                            autoplay=False,  # ä¸è‡ªåŠ¨æ’­æ”¾å½•åˆ¶çš„éŸ³é¢‘
                            show_download_button=False,  # éšè—ä¸‹è½½æŒ‰é’®
                            show_share_button=False,  # éšè—åˆ†äº«æŒ‰é’®
                            show_label=True,  # æ˜¾ç¤ºæ ‡ç­¾
                            waveform_options={"show_controls": False},  # éšè—éŸ³é¢‘æ§åˆ¶æ¡
                            interactive=True,  # å…è®¸ç”¨æˆ·äº¤äº’
                            type="filepath",  # è¿”å›æ–‡ä»¶è·¯å¾„è€ŒééŸ³é¢‘æ•°æ®
                            sources=["microphone"]  # ä»…å…è®¸éº¦å…‹é£è¾“å…¥
                        )
                        # å½•éŸ³çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸï¼Œç”±JavaScriptæ›´æ–°
                        recording_status = gr.HTML("", elem_id="recording_status", visible=True)
                
                # ç®€åŒ–çš„è¯­éŸ³å›å¤æ’­æ”¾ç»„ä»¶
                audio_output = gr.Audio(
                    label="Voice Output",  # ç§»é™¤æ ‡ç­¾
                    visible=True, 
                    autoplay=True, 
                    type="filepath",  # ä½¿ç”¨æ–‡ä»¶è·¯å¾„ç±»å‹
                    show_download_button=False,  # éšè—ä¸‹è½½æŒ‰é’®
                    show_share_button=False,  # éšè—åˆ†äº«æŒ‰é’®
                    elem_id="voice_reply_audio"  # æ·»åŠ å…ƒç´ IDä¾¿äºè°ƒè¯•
                )
                # æ·»åŠ JavaScriptä»¥åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                gr.HTML("""
                <script>
                function updateDebugInfo(message) {
                    const debugElement = document.getElementById('audio_debug_info');
                    if (debugElement) {
                        const timestamp = new Date().toLocaleTimeString();
                        debugElement.innerHTML += `<div>[${timestamp}] ${message}</div>`;
                        // ä¿æŒæœ€æ–°çš„æ¶ˆæ¯å¯è§
                        debugElement.scrollTop = debugElement.scrollHeight;
                    }
                }
                
                // ç›‘å¬éŸ³é¢‘å…ƒç´ äº‹ä»¶
                document.addEventListener('DOMNodeInserted', function(e) {
                    if (e.target.tagName === 'AUDIO') {
                        updateDebugInfo(`å‘ç°æ–°çš„éŸ³é¢‘å…ƒç´ : ${e.target.src.substring(0, 50)}...`);
                        
                        e.target.addEventListener('play', function() {
                            updateDebugInfo(`éŸ³é¢‘å¼€å§‹æ’­æ”¾: ${this.src.substring(0, 50)}...`);
                        });
                        
                        e.target.addEventListener('error', function() {
                            updateDebugInfo(`éŸ³é¢‘æ’­æ”¾é”™è¯¯: ${this.src.substring(0, 50)}... é”™è¯¯ä»£ç : ${this.error ? this.error.code : 'æœªçŸ¥'}`);
                        });
                        
                        e.target.addEventListener('canplay', function() {
                            updateDebugInfo(`éŸ³é¢‘å¯ä»¥æ’­æ”¾: ${this.src.substring(0, 50)}...`);
                        });
                    }
                });
                </script>
                """)
                
            # æ¨¡å‹å’Œæç¤ºé€‰æ‹©åŒºåŸŸ - é…ç½®AIä¸ªæ€§å’Œè¯­éŸ³é£æ ¼
            with gr.Column(scale=1):
                # MBTIæ€§æ ¼æ¨¡å‹é€‰æ‹© - å†³å®šAIå›å¤çš„æ€§æ ¼ç‰¹å¾
                lora_path = gr.Radio(
                    ["estj", "infp", "base_1", "base_2"],  # ä¸åŒMBTIæ€§æ ¼ç±»å‹æ¨¡å‹
                    label="Model Selection",  # æ ‡ç­¾
                    value="estj"  # é»˜è®¤é€‰æ‹©ESTJæ€§æ ¼æ¨¡å‹
                )
                
                # æç¤ºæ¨¡æ¿é€‰æ‹© - å†³å®šAIå›å¤çš„é£æ ¼å’Œè¯­æ°”
                prompt_choice = gr.Radio(
                    ["assist_estj", "assist_infp", "null"],  # ä¸åŒæç¤ºæ¨¡æ¿
                    label="Prompt Selection",  # æ ‡ç­¾
                    value="assist_estj"  # é»˜è®¤ä½¿ç”¨ESTJåŠ©æ‰‹æç¤º
                )
                
                # æ ¼å¼é€‰æ‹© - æ§åˆ¶æç¤ºæ ¼å¼ï¼Œé»˜è®¤éšè—
                promptFormat_choice = gr.Radio(
                    ["ordinary", "custom"],  # æ™®é€šæ ¼å¼æˆ–è‡ªå®šä¹‰æ ¼å¼
                    label="Format Selection",  # æ ‡ç­¾
                    value="ordinary",  # é»˜è®¤ä½¿ç”¨æ™®é€šæ ¼å¼
                    visible=False  # åœ¨UIä¸­éšè—æ­¤é€‰é¡¹
                )
                
                # è¯­éŸ³åˆæˆé£æ ¼é€‰æ‹© - æ§åˆ¶AIå›å¤çš„è¯­éŸ³ç‰¹å¾
                tts_choice = gr.Radio(
                    [
                        "Soft Female Voice - Cancan (Normal)",  # ç¿ç¿éŸ³è‰²-æ ‡å‡†è¯­é€Ÿ
                        "Energetic Female Voice - Cancan (Fast)",  # ç¿ç¿éŸ³è‰²-å¿«é€Ÿè¯­è°ƒé«˜
                        "Professional Foreign Voice - Stefan (Normal)",  # StefanéŸ³è‰²-æ ‡å‡†è¯­é€Ÿ
                        "Expressive Foreign Voice - Stefan (Fast)"  # StefanéŸ³è‰²-å¿«é€Ÿè¯­è°ƒé«˜
                    ],
                    label="Voice Style Selection",  # æ ‡ç­¾æ”¹ä¸ºè‹±æ–‡
                    value="Soft Female Voice - Cancan (Normal)"  # é»˜è®¤ä½¿ç”¨ç¿ç¿æ ‡å‡†è¯­é€Ÿ
                )
                
                # å›å¤è¯­è¨€é€‰æ‹© - æ§åˆ¶AIå›å¤çš„è¯­è¨€
                reply_language_choice = gr.Radio(
                    ["Chinese", "English", "Japanese"],  # ä¸åŒå›å¤è¯­è¨€(è‹±æ–‡æ˜¾ç¤º)ï¼Œå»æ‰æ³•è¯­é€‰é¡¹
                    label="Reply Language Selection",  # æ ‡ç­¾
                    value="English"  # é»˜è®¤ä½¿ç”¨è‹±æ–‡å›å¤
                )
                
                # ASRè¯­è¨€é€‰æ‹© - æ§åˆ¶è¯­éŸ³è¯†åˆ«çš„è¯­è¨€
                asr_language_choice = gr.Radio(
                    ["Chinese", "English"],  # ASRåªæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
                    label="ASR Language Selection",  # æ ‡ç­¾
                    value="English"  # é»˜è®¤ä½¿ç”¨è‹±æ–‡è¯†åˆ«
                )
                
                # æ¸…é™¤èŠå¤©æŒ‰é’® - é‡ç½®å¯¹è¯å†å²
                clear_btn = gr.Button("Clear Chat")
            
            # å­˜å‚¨èŠå¤©å†å²çš„çŠ¶æ€
            chat_history = gr.State([])
            
            # ç¡®ä¿éŸ³é¢‘è¾“å…¥ä¸èŠå¤©å‡½æ•°å…³è”ï¼ˆåœ¨å®šä¹‰æ‰€æœ‰å˜é‡åï¼‰
            # audio_input.change(fn=handle_chat, inputs=[audio_input, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice], outputs=[chatbot, chat_history, audio_output, audio_input])
            
            # # æ·»åŠ JavaScriptä»£ç ï¼Œç”¨äºæµè§ˆå™¨æœ¬åœ°TTS
            # js_code = """
            #     function browserTTS(text) {
            #         if ('speechSynthesis' in window) {
            #             // åˆ›å»ºè¯­éŸ³åˆæˆå®ä¾‹
            #             const utterance = new SpeechSynthesisUtterance(text);
            #             // è®¾ç½®è¯­éŸ³å‚æ•°
            #             utterance.rate = 1.0;  // è¯­é€Ÿ
            #             utterance.pitch = 1.0; // Pitch
            #             utterance.volume = 1.0; // Volume
            #             // Get Chinese voice
            #             const voices = window.speechSynthesis.getVoices();
            #             const chineseVoice = voices.find(voice => voice.lang.includes('zh'));
            #             if (chineseVoice) {
            #                 utterance.voice = chineseVoice;
            #             }
            #             // Play voice
            #             window.speechSynthesis.speak(utterance);
            #             return true;
            #         }
            #         return false;
            #     }
                
            #     // Listen for chat reply updates and add avatars
            #     document.addEventListener('DOMContentLoaded', function() {
            #         console.log('éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): DOMåŠ è½½å®Œæˆï¼Œå¼€å§‹ç›‘å¬éŸ³é¢‘å…ƒç´ ');
                    
            #         // ç›‘å¬éŸ³é¢‘å…ƒç´ åŠ è½½
            #         document.addEventListener('play', function(e) {
            #             if (e.target.tagName === 'AUDIO') {
            #                 console.log('éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): éŸ³é¢‘å¼€å§‹æ’­æ”¾', e.target.src);
            #             }
            #         }, true);
                    
            #         document.addEventListener('error', function(e) {
            #             if (e.target.tagName === 'AUDIO') {
            #                 console.log('éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): éŸ³é¢‘æ’­æ”¾é”™è¯¯', e.target.src, e.target.error);
            #             }
            #         }, true);
                    
            #         // å®šæœŸæ£€æŸ¥éŸ³é¢‘å…ƒç´ 
            #         setInterval(function() {
            #             const audioElements = document.querySelectorAll('audio');
            #             console.log(`éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): å½“å‰é¡µé¢æœ‰ ${audioElements.length} ä¸ªéŸ³é¢‘å…ƒç´ `);
            #             audioElements.forEach((audio, index) => {
            #                 console.log(`éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): éŸ³é¢‘å…ƒç´  ${index+1}:`, {
            #                     src: audio.src,
            #                     readyState: audio.readyState,
            #                     paused: audio.paused,
            #                     ended: audio.ended,
            #                     error: audio.error
            #                 });
            #             });
            #         }, 5000);
                    
            #         // Regularly check for new chat messages
            #         setInterval(function() {
            #             // TTS processing
            #             const ttsChoice = document.querySelector('input[name="tts_choice"]:checked');
            #             if (ttsChoice && ttsChoice.value === "Browser Local TTS") {
            #                 console.log('éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): ä½¿ç”¨æµè§ˆå™¨æœ¬åœ°TTS');
            #                 const chatMessages = document.querySelectorAll('.message:not(.user)');
            #                 const lastMessage = chatMessages[chatMessages.length - 1];
            #                 if (lastMessage && !lastMessage.hasAttribute('data-tts-processed')) {
            #                     const messageText = lastMessage.textContent.trim();
            #                     if (messageText) {
            #                         console.log('éŸ³é¢‘æ’­æ”¾è°ƒè¯•(JS): å°è¯•ä½¿ç”¨æµè§ˆå™¨TTSæ’­æ”¾æ¶ˆæ¯', messageText.substring(0, 50) + '...');
            #                         browserTTS(messageText);
            #                         lastMessage.setAttribute('data-tts-processed', 'true');
            #                     }
            #                 }
            #             }
                        
            #             // Add avatars to all messages
            #             addAvatarsToMessages();
            #         }, 1000);
                    
            #         // Function to add avatars
            #         function addAvatarsToMessages() {
            #             // Get all message elements
            #             const userMessages = document.querySelectorAll('.message.user');
            #             const botMessages = document.querySelectorAll('.message.bot');
                        
            #             // ä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ å¤´åƒ
            #             userMessages.forEach(msg => {
            #                 if (!msg.hasAttribute('data-avatar-added')) {
            #                     const avatar = document.createElement('div');
            #                     avatar.className = 'user-avatar';
            #                     avatar.style.cssText = 'position:absolute;left:-40px;top:0;width:35px;height:35px;background-image:url("https://cdn.jsdelivir.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f464.png");background-size:cover;border-radius:50%;';
                                
            #                     // ç¡®ä¿æ¶ˆæ¯å®¹å™¨æ˜¯ç›¸å¯¹å®šä½
            #                     msg.style.position = 'relative';
            #                     msg.style.marginLeft = '40px';
            #                     msg.style.marginBottom = '10px';
                                
            #                     // æ’å…¥å¤´åƒ
            #                     msg.insertBefore(avatar, msg.firstChild);
            #                     msg.setAttribute('data-avatar-added', 'true');
            #                 }
            #             });
                        
            #             // ä¸ºæœºå™¨äººæ¶ˆæ¯æ·»åŠ å¤´åƒ
            #             botMessages.forEach(msg => {
            #                 if (!msg.hasAttribute('data-avatar-added')) {
            #                     const avatar = document.createElement('div');
            #                     avatar.className = 'bot-avatar';
            #                     avatar.style.cssText = 'position:absolute;left:-40px;top:0;width:35px;height:35px;background-image:url("https://cdn.jsdelivir.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f916.png");background-size:cover;border-radius:50%;';
                                
            #                     // ç¡®ä¿æ¶ˆæ¯å®¹å™¨æ˜¯ç›¸å¯¹å®šä½
            #                     msg.style.position = 'relative';
            #                     msg.style.marginLeft = '40px';
            #                     msg.style.marginBottom = '10px';
                                
            #                     // æ’å…¥å¤´åƒ
            #                     msg.insertBefore(avatar, msg.firstChild);
            #                     msg.setAttribute('data-avatar-added', 'true');
            #                 }
            #             });
            #         }
            #     });
            #     """
            # gr.HTML("<script>" + js_code + "</script>", visible=False)
        
        # äº‹ä»¶å¤„ç†éƒ¨åˆ† - å®šä¹‰UIç»„ä»¶çš„äº¤äº’è¡Œä¸º
        # æäº¤æŒ‰é’®ç‚¹å‡»äº‹ä»¶ - å¤„ç†æ–‡æœ¬è¾“å…¥å¹¶ç”Ÿæˆå›å¤
        submit_btn.click(
            fn=handle_chat,  # å¤„ç†å‡½æ•°
            # è¾“å…¥å‚æ•°åˆ—è¡¨
            inputs=[msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice],
            # è¾“å‡ºå‚æ•°åˆ—è¡¨
            outputs=[chatbot, chat_history, audio_output, msg],
            api_name="submit"  # APIç«¯ç‚¹åç§°
        )
        
        # æ–‡æœ¬æ¡†å›è½¦æäº¤äº‹ä»¶ - ä¸æäº¤æŒ‰é’®åŠŸèƒ½ç›¸åŒ
        msg.submit(
            fn=handle_chat,  # å¤„ç†å‡½æ•°
            # è¾“å…¥å‚æ•°åˆ—è¡¨
            inputs=[msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice],
            # è¾“å‡ºå‚æ•°åˆ—è¡¨
            outputs=[chatbot, chat_history, audio_output, msg]
        )
        
        # éŸ³é¢‘è¾“å…¥å¤„ç†äº‹ä»¶ï¼ˆå½•éŸ³å®Œæˆåè‡ªåŠ¨å¤„ç†ï¼‰
        audio_input.change(
            fn=handle_audio,  # å¤„ç†å‡½æ•°
            # è¾“å…¥å‚æ•°åˆ—è¡¨
            inputs=[audio_input, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice],
            # è¾“å‡ºå‚æ•°åˆ—è¡¨
            outputs=[chatbot, chat_history, audio_output, msg],
            api_name="audio"  # APIç«¯ç‚¹åç§°
        )
        
        # éº¦å…‹é£å½•éŸ³åœæ­¢äº‹ä»¶ - å½•éŸ³ç»“æŸåè‡ªåŠ¨å¤„ç†è¯­éŸ³è¾“å…¥
        # audio_input.stop_recording(
        #     fn=handle_chat,  # å¤„ç†å‡½æ•°
        #     # ç¡®ä¿å‚æ•°é¡ºåºä¸handle_chatå‡½æ•°å®šä¹‰ä¸€è‡´
        #     inputs=[msg, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, audio_input],
        #     # è¾“å‡ºå‚æ•°åˆ—è¡¨
        #     outputs=[chatbot, chat_history, audio_output, msg],
        #     api_name="mic_recording"  # APIç«¯ç‚¹åç§°
        # )
        
        # æ–‡ä»¶ä¸Šä¼ äº‹ä»¶ - å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        upload_btn.upload(
            fn=handle_upload,  # å¤„ç†å‡½æ•°
            # è¾“å…¥å‚æ•°åˆ—è¡¨
            inputs=[upload_btn, chatbot, lora_path, prompt_choice, promptFormat_choice, tts_choice, reply_language_choice, asr_language_choice],
            # è¾“å‡ºå‚æ•°åˆ—è¡¨
            outputs=[chatbot, chat_history, audio_output, msg],
            api_name="upload"  # APIç«¯ç‚¹åç§°
        )
        
        # éŸ³é¢‘è¾“å…¥å·²ç»åœ¨ä¸Šé¢çš„audio_input.changeäº‹ä»¶ä¸­å¤„ç†
        
        # æ¸…é™¤èŠå¤©æŒ‰é’®äº‹ä»¶ - é‡ç½®å¯¹è¯å†å²
        clear_btn.click(
            fn=lambda: ([], []),  # è¿”å›ä¸¤ä¸ªç©ºåˆ—è¡¨ï¼Œåˆ†åˆ«ç”¨äºæ¸…ç©ºchatbotå’Œchat_history
            inputs=None,  # ä¸éœ€è¦è¾“å…¥å‚æ•°
            outputs=[chatbot, chat_history],  # æ¸…ç©ºè¿™ä¸¤ä¸ªç»„ä»¶
            api_name="clear"  # APIç«¯ç‚¹åç§°
        )
        
        # è‡ªå®šä¹‰CSS - è®¾ç½®åº”ç”¨ç¨‹åºçš„è§†è§‰æ ·å¼å’Œå¸ƒå±€
        gr.Markdown("""
        <style>
        /* è®¾ç½®æ•´ä½“å®¹å™¨å­—ä½“ - ä½¿ç”¨ç°ä»£æ— è¡¬çº¿å­—ä½“ç³»åˆ— */
        .gradio-container {
            font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        }
        
        /* èŠå¤©æ¡†ä¸»å®¹å™¨æ ·å¼ - æ·»åŠ åœ†è§’å’Œé˜´å½±æ•ˆæœ */
        #chatbot {
            border-radius: 10px;                /* åœ†è§’è¾¹æ¡† */
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); /* è½»å¾®é˜´å½±æ•ˆæœ */
            padding-left: 10px;                /* ä¸ºå¤´åƒç•™å‡ºç©ºé—´ */
        }
        
        /* è°ƒæ•´èŠå¤©å®¹å™¨å†…éƒ¨å¸ƒå±€ - å¢åŠ å†…è¾¹è· */
        .chatbot {
            padding: 15px;                      /* å†…éƒ¨å¡«å…… */
        }
        
        /* ç¡®ä¿æ¶ˆæ¯å®¹å™¨æœ‰è¶³å¤Ÿç©ºé—´æ˜¾ç¤ºå¤´åƒ */
        .message-wrap {
            position: relative;                 /* ç›¸å¯¹å®šä½ */
            padding-left: 10px;                /* å·¦ä¾§å¡«å…… */
        }
        
        /* ç”¨æˆ·æ¶ˆæ¯æ°”æ³¡æ ·å¼ - ä½¿ç”¨æµ…è“è‰²èƒŒæ™¯ */
        #chatbot .user {
            background-color: #f0f4f9;          /* æµ…è“è‰²èƒŒæ™¯ */
            border-radius: 10px;                /* åœ†è§’è¾¹æ¡† */
            padding: 10px 15px;                 /* å†…éƒ¨å¡«å…… */
            margin-bottom: 10px;                /* åº•éƒ¨å¤–è¾¹è· */
            margin-left: 40px !important;       /* å·¦ä¾§ç•™å‡ºå¤´åƒç©ºé—´ */
            position: relative !important;      /* ç›¸å¯¹å®šä½ */
        }
        
        /* å¼ºåˆ¶è¦†ç›–æ‰€æœ‰å¯èƒ½çš„Gradioå¤´åƒé€‰æ‹©å™¨ - ç”¨æˆ·å¤´åƒ */
        #chatbot .user::before,
        .chatbot .user::before,
        [data-testid="chatbot"] .user::before,
        .message-wrap .user::before,
        .message.user::before,
        .message-wrap .message.user::before,
        .chatbot .message.user::before {
            content: 'ğŸ‘¤' !important;            /* ç”¨æˆ·è¡¨æƒ…ç¬¦å· */
            position: absolute !important;      /* ç»å¯¹å®šä½ */
            left: -40px !important;             /* å·¦ä¾§ä½ç½® */
            top: 50% !important;                /* å‚ç›´å±…ä¸­ä½ç½® */
            transform: translateY(-50%) !important; /* å‚ç›´å±…ä¸­å¯¹é½ */
            width: 35px !important;             /* å¤´åƒå®½åº¦ */
            height: 35px !important;            /* å¤´åƒé«˜åº¦ */
            background-color: #4CAF50 !important; /* ç»¿è‰²èƒŒæ™¯ */
            background-image: none !important;  /* å¼ºåˆ¶ç§»é™¤èƒŒæ™¯å›¾ç‰‡ */
            color: white !important;            /* ç™½è‰²è¡¨æƒ…ç¬¦å· */
            display: flex !important;           /* å¼¹æ€§å¸ƒå±€ */
            align-items: center !important;     /* å‚ç›´å±…ä¸­ */
            justify-content: center !important; /* æ°´å¹³å±…ä¸­ */
            font-size: 18px !important;         /* è¡¨æƒ…ç¬¦å·å¤§å° */
            border-radius: 50% !important;      /* åœ†å½¢å¤´åƒ */
            z-index: 9999 !important;           /* æœ€é«˜å±‚çº§ */
            box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important; /* è½»å¾®é˜´å½± */
        }
        
        /* å¼ºåˆ¶è¦†ç›–æ‰€æœ‰å¯èƒ½çš„Gradioå¤´åƒé€‰æ‹©å™¨ - æœºå™¨äººå¤´åƒ */
        #chatbot .bot::before,
        .chatbot .bot::before,
        [data-testid="chatbot"] .bot::before,
        .message-wrap .bot::before,
        .message.bot::before,
        .message-wrap .message.bot::before,
        .chatbot .message.bot::before {
            content: 'ğŸ¤–' !important;            /* æœºå™¨äººè¡¨æƒ…ç¬¦å· */
            position: absolute !important;      /* ç»å¯¹å®šä½ */
            left: -40px !important;             /* å·¦ä¾§ä½ç½® */
            top: 50% !important;                /* å‚ç›´å±…ä¸­ä½ç½® */
            transform: translateY(-50%) !important; /* å‚ç›´å±…ä¸­å¯¹é½ */
            width: 35px !important;             /* å¤´åƒå®½åº¦ */
            height: 35px !important;            /* å¤´åƒé«˜åº¦ */
            background-color: #2196F3 !important; /* è“è‰²èƒŒæ™¯ */
            background-image: none !important;  /* å¼ºåˆ¶ç§»é™¤èƒŒæ™¯å›¾ç‰‡ */
            color: white !important;            /* ç™½è‰²è¡¨æƒ…ç¬¦å· */
            display: flex !important;           /* å¼¹æ€§å¸ƒå±€ */
            align-items: center !important;     /* å‚ç›´å±…ä¸­ */
            justify-content: center !important; /* æ°´å¹³å±…ä¸­ */
            font-size: 18px !important;         /* è¡¨æƒ…ç¬¦å·å¤§å° */
            border-radius: 50% !important;      /* åœ†å½¢å¤´åƒ */
            z-index: 9999 !important;           /* æœ€é«˜å±‚çº§ */
            box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important; /* è½»å¾®é˜´å½± */
        }

        /* ä¼˜åŒ–éŸ³é¢‘è¾“å…¥ç»„ä»¶æ˜¾ç¤º - ç§»é™¤è¾¹æ¡†å¹¶æ·»åŠ ä¸Šè¾¹è· */
        #mic_input {
            margin-top: 10px;                   /* é¡¶éƒ¨å¤–è¾¹è· */
            border: none;                       /* ç§»é™¤è¾¹æ¡† */
        }
        
        /* éšè—GradioåŸç”Ÿçš„å½•éŸ³æŒ‰é’®ï¼ˆä»…ä¿ç•™éŸ³é¢‘æ’­æ”¾æ§ä»¶ï¼‰ */
        #mic_input .controls > button:not(.play-button) {
            display: none !important;           /* éšè—éæ’­æ”¾æŒ‰é’® */
        }
        
        /* ç¡®ä¿å½•éŸ³æŒ‰é’®å¯¹ç”¨æˆ·ä¸å¯è§ä½†JSå¯è®¿é—® - ç”¨äºè‡ªå®šä¹‰å½•éŸ³æ§åˆ¶ */
        #mic_input .record, #mic_input .stop {
            opacity: 0 !important;              /* é€æ˜åº¦ä¸º0 */
            position: absolute !important;      /* ç»å¯¹å®šä½ */
            pointer-events: all !important;     /* å…è®¸JSç‚¹å‡»äº‹ä»¶ */
            width: 1px !important;              /* æœ€å°å®½åº¦ */
            height: 1px !important;             /* æœ€å°é«˜åº¦ */
            overflow: hidden !important;        /* éšè—æº¢å‡ºéƒ¨åˆ† */
            z-index: -1 !important;             /* è´Ÿå±‚çº§ç¡®ä¿åœ¨è§†è§‰ä¸Šéšè— */
        }
        
        /* ç¾åŒ–éº¦å…‹é£æŒ‰é’® - ä½¿ç”¨ç»¿è‰²èƒŒæ™¯å’Œåœ†è§’ */
        #mic_button {
            background-color: #4CAF50;          /* ç»¿è‰²èƒŒæ™¯ */
            color: white;                       /* ç™½è‰²æ–‡å­— */
            border: none;                       /* æ— è¾¹æ¡† */
            border-radius: 20px;                /* åœ†è§’è¾¹æ¡† */
            padding: 8px 16px;                  /* å†…éƒ¨å¡«å…… */
            cursor: pointer;                    /* é¼ æ ‡æŒ‡é’ˆæ ·å¼ */
            width: 100%;                        /* å®½åº¦100% */
            transition: all 0.3s ease;          /* å¹³æ»‘è¿‡æ¸¡æ•ˆæœ */
        }
        
        /* éº¦å…‹é£æŒ‰é’®æ‚¬åœæ•ˆæœ - è½»å¾®æ”¾å¤§å¹¶æ·»åŠ é˜´å½± */
        #mic_button:hover {
            transform: scale(1.05);              /* æ”¾å¤§æ•ˆæœ */
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); /* è½»å¾®é˜´å½± */
        }
        
        /* å½•éŸ³çŠ¶æ€æ˜¾ç¤ºæ ·å¼ - å±…ä¸­æ˜¾ç¤ºå½•éŸ³æ—¶é—´ */
        #recording_status {
            margin-top: 5px;                    /* é¡¶éƒ¨å¤–è¾¹è· */
            text-align: center;                 /* æ–‡å­—å±…ä¸­ */
            font-size: 12px;                    /* å°å­—ä½“ */
        }
        
        /* éŸ³é¢‘æ¶ˆæ¯æ ·å¼ - æ·»åŠ ä¸Šè¾¹è·å’Œé¼ æ ‡æŒ‡é’ˆæ ·å¼ */
        .audio-message {
            margin-top: 10px;                   /* é¡¶éƒ¨å¤–è¾¹è· */
            cursor: pointer;                    /* é¼ æ ‡æŒ‡é’ˆæ ·å¼ */
        }
        
        /* éŸ³é¢‘æ¶ˆæ¯æ‚¬åœæ•ˆæœ - è½»å¾®é€æ˜ */
        .audio-message:hover {
            opacity: 0.8;                        /* è½»å¾®é€æ˜ */
        }
        
        /* éº¦å…‹é£æŒ‰é’®è¿‡æ¸¡æ•ˆæœ - å¹³æ»‘åŠ¨ç”» */
        #mic_button {
            transition: all 0.3s ease;          /* å¹³æ»‘è¿‡æ¸¡æ•ˆæœ */
        }
        
        /* éº¦å…‹é£æŒ‰é’®æ‚¬åœæ”¾å¤§æ•ˆæœ */
        #mic_button:hover {
            transform: scale(1.1);              /* æ”¾å¤§æ•ˆæœ */
        }
        
        /* éšè—éº¦å…‹é£é€‰æ‹©ä¸‹æ‹‰èœå• */
        .mic-wrap select, 
        .mic-wrap .wrap-inner > div:first-child,
        #mic_input .wrap-inner > div:first-child,
        #mic_input select {
            display: none !important;
        }
        </style>
        """)
    
    return demo

# ä¸»å‡½æ•° - åº”ç”¨ç¨‹åºå…¥å£ç‚¹
def main():
    import argparse
    
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨ - ç”¨äºé…ç½®æœåŠ¡å™¨å¯åŠ¨å‚æ•°
    parser = argparse.ArgumentParser(description='å¯åŠ¨MBTIèŠå¤©åº”ç”¨')
    # æ·»åŠ ç«¯å£å‚æ•°ï¼Œé»˜è®¤ä¸º8003
    parser.add_argument('--server_port', type=int, default=8003, help='æœåŠ¡å™¨ç«¯å£å·')
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # åˆ›å»ºGradioç•Œé¢
    demo = create_interface()
    # å¯åŠ¨WebæœåŠ¡å™¨
    # share=True: ç”Ÿæˆå¯å…¬å¼€è®¿é—®çš„ä¸´æ—¶URL
    # server_name="0.0.0.0": ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£
    # server_port: ä½¿ç”¨æŒ‡å®šçš„ç«¯å£å·
    # allowed_paths=["static"]: å…è®¸è®¿é—®staticç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆç”¨äºéŸ³é¢‘æ–‡ä»¶ï¼‰
    demo.launch(share=True, server_name="0.0.0.0", server_port=args.server_port, favicon_path=None, allowed_paths=["static"])

# ç¨‹åºå…¥å£ç‚¹ - å½“è„šæœ¬ç›´æ¥è¿è¡Œæ—¶æ‰§è¡Œmainå‡½æ•°
if __name__ == "__main__":
    main()